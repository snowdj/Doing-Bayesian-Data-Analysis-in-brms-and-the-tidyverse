<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10 Model Comparison and Hierarchical Modeling | Doing Bayesian Data Analysis in brms and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="10 Model Comparison and Hierarchical Modeling | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10 Model Comparison and Hierarchical Modeling | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-02-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hierarchical-models.html"/>
<link rel="next" href="null-hypothesis-significance-testing.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>What and why</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#caution-work-in-progress"><i class="fa fa-check"></i>Caution: Work in progress</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#weve-come-so-far"><i class="fa fa-check"></i>We’ve come so far!</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#were-not-done-yet-and-i-could-use-your-help."><i class="fa fa-check"></i>We’re not done yet and I could use your help.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html"><i class="fa fa-check"></i><b>1</b> What’s in This Book (Read This First!)</a><ul>
<li class="chapter" data-level="1.1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#real-people-can-read-this-book"><i class="fa fa-check"></i><b>1.1</b> Real people can read this book</a></li>
<li class="chapter" data-level="1.2" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-in-this-book"><i class="fa fa-check"></i><b>1.2</b> What’s in this book</a></li>
<li class="chapter" data-level="1.3" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-new-in-the-second-edition"><i class="fa fa-check"></i><b>1.3</b> What’s new in the second edition</a></li>
<li class="chapter" data-level="1.4" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#gimme-feedback-be-polite"><i class="fa fa-check"></i><b>1.4</b> Gimme feedback (be polite)</a></li>
<li class="chapter" data-level="1.5" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#thank-you"><i class="fa fa-check"></i><b>1.5</b> Thank you!</a></li>
<li class="chapter" data-level="" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>I THE BASICS: MODELS, PROBABILITY, BAYES’ RULE, AND R</b></span></li>
<li class="chapter" data-level="2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Introduction: Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#bayesian-inference-is-reallocation-of-credibility-across-possibilities"><i class="fa fa-check"></i><b>2.1</b> Bayesian inference is reallocation of credibility across possibilities</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#data-are-noisy-and-inferences-are-probabilistic."><i class="fa fa-check"></i><b>2.1.1</b> Data are noisy and inferences are probabilistic.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#possibilities-are-parameter-values-in-descriptive-models"><i class="fa fa-check"></i><b>2.2</b> Possibilities are parameter values in descriptive models</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.3</b> The steps of Bayesian data analysis</a></li>
<li class="chapter" data-level="" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html"><i class="fa fa-check"></i><b>3</b> The R Programming Language</a><ul>
<li class="chapter" data-level="3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-software"><i class="fa fa-check"></i><b>3.1</b> Get the software</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-look-at-rstudio."><i class="fa fa-check"></i><b>3.1.1</b> A look at RStudio.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-simple-example-of-r-in-action"><i class="fa fa-check"></i><b>3.2</b> A simple example of R in action</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-programs-used-with-this-book."><i class="fa fa-check"></i><b>3.2.1</b> Get the programs used with this book.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#basic-commands-and-operators-in-r"><i class="fa fa-check"></i><b>3.3</b> Basic commands and operators in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#getting-help-in-r."><i class="fa fa-check"></i><b>3.3.1</b> Getting help in R.</a></li>
<li class="chapter" data-level="3.3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#arithmetic-and-logical-operators."><i class="fa fa-check"></i><b>3.3.2</b> Arithmetic and logical operators.</a></li>
<li class="chapter" data-level="3.3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#assignment-relational-operators-and-tests-of-equality."><i class="fa fa-check"></i><b>3.3.3</b> Assignment, relational operators, and tests of equality.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-types"><i class="fa fa-check"></i><b>3.4</b> Variable types</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#vector."><i class="fa fa-check"></i><b>3.4.1</b> Vector.</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#factor."><i class="fa fa-check"></i><b>3.4.2</b> Factor.</a></li>
<li class="chapter" data-level="3.4.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#matrix-and-array."><i class="fa fa-check"></i><b>3.4.3</b> Matrix and array.</a></li>
<li class="chapter" data-level="3.4.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#list-and-data-frame."><i class="fa fa-check"></i><b>3.4.4</b> List and data frame.</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#loading-and-saving-data"><i class="fa fa-check"></i><b>3.5</b> Loading and saving data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#the-read.csv-read_csv-and-read.table-read_table-functions."><i class="fa fa-check"></i><b>3.5.1</b> The <del>read.csv</del> <code>read_csv()</code> and <del>read.table</del> <code>read_table()</code> functions.</a></li>
<li class="chapter" data-level="3.5.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#saving-data-from-r."><i class="fa fa-check"></i><b>3.5.2</b> Saving data from R.</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#some-utility-functions"><i class="fa fa-check"></i><b>3.6</b> Some utility functions</a></li>
<li class="chapter" data-level="3.7" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-in-r"><i class="fa fa-check"></i><b>3.7</b> Programming in R</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-names-in-r."><i class="fa fa-check"></i><b>3.7.1</b> Variable names in R.</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#running-a-program."><i class="fa fa-check"></i><b>3.7.2</b> Running a program.</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-a-function."><i class="fa fa-check"></i><b>3.7.3</b> Programming a function.</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#conditions-and-loops."><i class="fa fa-check"></i><b>3.7.4</b> Conditions and loops.</a></li>
<li class="chapter" data-level="3.7.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#measuring-processing-time."><i class="fa fa-check"></i><b>3.7.5</b> Measuring processing time.</a></li>
<li class="chapter" data-level="3.7.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#debugging."><i class="fa fa-check"></i><b>3.7.6</b> Debugging.</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#graphical-plots-opening-and-saving"><i class="fa fa-check"></i><b>3.8</b> Graphical plots: Opening and saving</a></li>
<li class="chapter" data-level="" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html"><i class="fa fa-check"></i><b>4</b> What is This Stuff Called Probability?</a><ul>
<li class="chapter" data-level="4.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#the-set-of-all-possible-events"><i class="fa fa-check"></i><b>4.1</b> The set of all possible events</a></li>
<li class="chapter" data-level="4.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-outside-or-inside-the-head"><i class="fa fa-check"></i><b>4.2</b> Probability: Outside or inside the head</a><ul>
<li class="chapter" data-level="4.2.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#outside-the-head-long-run-relative-frequency."><i class="fa fa-check"></i><b>4.2.1</b> Outside the head: Long-run relative frequency.</a></li>
<li class="chapter" data-level="4.2.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#inside-the-head-subjective-belief."><i class="fa fa-check"></i><b>4.2.2</b> Inside the head: Subjective belief.</a></li>
<li class="chapter" data-level="4.2.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probabilities-assign-numbers-to-possibilities."><i class="fa fa-check"></i><b>4.2.3</b> Probabilities assign numbers to possibilities.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-distributions"><i class="fa fa-check"></i><b>4.3</b> Probability distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#discrete-distributions-probability-mass."><i class="fa fa-check"></i><b>4.3.1</b> Discrete distributions: Probability mass.</a></li>
<li class="chapter" data-level="4.3.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#continuous-distributions-rendezvous-with-density."><i class="fa fa-check"></i><b>4.3.2</b> Continuous distributions: Rendezvous with density.</a></li>
<li class="chapter" data-level="4.3.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#mean-and-variance-of-a-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Mean and variance of a distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#highest-density-interval-hdi."><i class="fa fa-check"></i><b>4.3.4</b> Highest density interval (HDI).</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#two-way-distributions"><i class="fa fa-check"></i><b>4.4</b> Two-way distributions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#conditional-probability."><i class="fa fa-check"></i><b>4.4.1</b> Conditional probability.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-rule-1"><i class="fa fa-check"></i><b>5.1</b> Bayes’ rule</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#derived-from-definitions-of-conditional-probability."><i class="fa fa-check"></i><b>5.1.1</b> Derived from definitions of conditional probability.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule.html"><a href="bayes-rule.html#applied-to-parameters-and-data"><i class="fa fa-check"></i><b>5.2</b> Applied to parameters and data</a></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule.html"><a href="bayes-rule.html#complete-examples-estimating-bias-in-a-coin"><i class="fa fa-check"></i><b>5.3</b> Complete examples: Estimating bias in a coin</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-sample-size-on-the-posterior."><i class="fa fa-check"></i><b>5.3.1</b> Influence of sample size on the posterior.</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-prior-on-the-posterior."><i class="fa fa-check"></i><b>5.3.2</b> Influence of prior on the posterior.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule.html"><a href="bayes-rule.html#why-bayesian-inference-can-be-difficult"><i class="fa fa-check"></i><b>5.4</b> Why Bayesian inference can be difficult</a></li>
<li class="chapter" data-level="" data-path="bayes-rule.html"><a href="bayes-rule.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="bayes-rule.html"><a href="bayes-rule.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>II ALL THE FUNDAMENTALS APPLIED TO INFERRING A BINOMIAL PROBABILITY</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-likelihood-function-the-bernoulli-distribution"><i class="fa fa-check"></i><b>6.1</b> The likelihood function: The Bernoulli distribution</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-description-of-credibilities-the-beta-distribution"><i class="fa fa-check"></i><b>6.2</b> A description of credibilities: The beta distribution</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#specifying-a-beta-prior."><i class="fa fa-check"></i><b>6.2.1</b> Specifying a beta prior.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-posterior-beta"><i class="fa fa-check"></i><b>6.3</b> The posterior beta</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#posterior-is-compromise-of-prior-and-likelihood."><i class="fa fa-check"></i><b>6.3.1</b> Posterior is compromise of prior and likelihood.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#examples"><i class="fa fa-check"></i><b>6.4</b> Examples</a><ul>
<li class="chapter" data-level="6.4.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.1</b> Prior knowledge expressed as a beta distribution.</a></li>
<li class="chapter" data-level="6.4.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-that-cannot-be-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.2</b> Prior knowledge that cannot be expressed as a beta distribution.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#summary"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#approximating-a-distribution-with-a-large-sample"><i class="fa fa-check"></i><b>7.1</b> Approximating a distribution with a large sample</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-simple-case-of-the-metropolis-algorithm"><i class="fa fa-check"></i><b>7.2</b> A simple case of the Metropolis algorithm</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-politician-stumbles-upon-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.2.1</b> A politician stumbles upon the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-random-walk."><i class="fa fa-check"></i><b>7.2.2</b> A random walk.</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#general-properties-of-a-random-walk."><i class="fa fa-check"></i><b>7.2.3</b> General properties of a random walk.</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#why-we-care."><i class="fa fa-check"></i><b>7.2.4</b> Why we care.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-metropolis-algorithm-more-generally"><i class="fa fa-check"></i><b>7.3</b> The Metropolis algorithm more generally</a><ul>
<li class="chapter" data-level="7.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#metropolis-algorithm-applied-to-bernoulli-likelihood-and-beta-prior."><i class="fa fa-check"></i><b>7.3.1</b> Metropolis algorithm applied to Bernoulli likelihood and beta prior.</a></li>
<li class="chapter" data-level="7.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#summary-of-metropolis-algorithm."><i class="fa fa-check"></i><b>7.3.2</b> Summary of Metropolis algorithm.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#toward-gibbs-sampling-estimating-two-coin-biases"><i class="fa fa-check"></i><b>7.4</b> Toward Gibbs sampling: Estimating two coin biases</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#prior-likelihood-and-posterior-for-two-biases."><i class="fa fa-check"></i><b>7.4.1</b> Prior, likelihood and posterior for two biases.</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-exact-formal-analysis."><i class="fa fa-check"></i><b>7.4.2</b> The posterior via exact formal analysis.</a></li>
<li class="chapter" data-level="7.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.4.3</b> The posterior via the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-hamiltonian-monte-carlo-sampling."><i class="fa fa-check"></i><b>7.4.4</b> <del>Gibbs</del> Hamiltonian Monte Carlo sampling.</a></li>
<li class="chapter" data-level="7.4.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#is-there-a-difference-between-biases"><i class="fa fa-check"></i><b>7.4.5</b> Is there a difference between biases?</a></li>
<li class="chapter" data-level="7.4.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#terminology-mcmc."><i class="fa fa-check"></i><b>7.4.6</b> Terminology: MCMC.</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness-accuracy-and-efficiency"><i class="fa fa-check"></i><b>7.5</b> MCMC representativeness, accuracy, and efficiency</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness."><i class="fa fa-check"></i><b>7.5.1</b> MCMC representativeness.</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-accuracy."><i class="fa fa-check"></i><b>7.5.2</b> MCMC accuracy.</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-efficiency."><i class="fa fa-check"></i><b>7.5.3</b> MCMC efficiency.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-brms.html"><a href="jags-brms.html"><i class="fa fa-check"></i><b>8</b> <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-brms.html"><a href="jags-brms.html#jags-brms-and-its-relation-to-r"><i class="fa fa-check"></i><b>8.1</b> <del>JAGS</del> brms and its relation to R</a></li>
<li class="chapter" data-level="8.2" data-path="jags-brms.html"><a href="jags-brms.html#a-complete-example"><i class="fa fa-check"></i><b>8.2</b> A complete example</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-brms.html"><a href="jags-brms.html#load-data."><i class="fa fa-check"></i><b>8.2.1</b> Load data.</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-brms.html"><a href="jags-brms.html#specify-model."><i class="fa fa-check"></i><b>8.2.2</b> Specify model.</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-brms.html"><a href="jags-brms.html#initialize-chains."><i class="fa fa-check"></i><b>8.2.3</b> Initialize chains.</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-brms.html"><a href="jags-brms.html#generate-chains."><i class="fa fa-check"></i><b>8.2.4</b> Generate chains.</a></li>
<li class="chapter" data-level="8.2.5" data-path="jags-brms.html"><a href="jags-brms.html#examine-chains."><i class="fa fa-check"></i><b>8.2.5</b> Examine chains.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-brms.html"><a href="jags-brms.html#simplified-scripts-for-frequently-used-analyses"><i class="fa fa-check"></i><b>8.3</b> Simplified scripts for frequently used analyses</a></li>
<li class="chapter" data-level="8.4" data-path="jags-brms.html"><a href="jags-brms.html#example-difference-of-biases"><i class="fa fa-check"></i><b>8.4</b> Example: Difference of biases</a></li>
<li class="chapter" data-level="8.5" data-path="jags-brms.html"><a href="jags-brms.html#sampling-from-the-prior-distribution-in-jags-brms"><i class="fa fa-check"></i><b>8.5</b> Sampling from the prior distribution in <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="8.6" data-path="jags-brms.html"><a href="jags-brms.html#probability-distributions-available-in-jags-brms"><i class="fa fa-check"></i><b>8.6</b> Probability distributions available in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.6.1" data-path="jags-brms.html"><a href="jags-brms.html#defining-new-likelihood-functions."><i class="fa fa-check"></i><b>8.6.1</b> Defining new likelihood functions.</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="jags-brms.html"><a href="jags-brms.html#faster-sampling-with-parallel-processing-in-runjags-brmsbrm"><i class="fa fa-check"></i><b>8.7</b> Faster sampling with parallel processing in <del>runjags</del> <code>brms::brm()</code></a></li>
<li class="chapter" data-level="8.8" data-path="jags-brms.html"><a href="jags-brms.html#tips-for-expanding-jags-brms-models"><i class="fa fa-check"></i><b>8.8</b> Tips for expanding <del>JAGS</del> brms models</a></li>
<li class="chapter" data-level="" data-path="jags-brms.html"><a href="jags-brms.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="jags-brms.html"><a href="jags-brms.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-single-coin-from-a-single-mint"><i class="fa fa-check"></i><b>9.1</b> A single coin from a single mint</a><ul>
<li class="chapter" data-level="9.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation."><i class="fa fa-check"></i><b>9.1.1</b> Posterior via grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#multiple-coins-from-a-single-mint"><i class="fa fa-check"></i><b>9.2</b> Multiple coins from a single mint</a><ul>
<li class="chapter" data-level="9.2.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation.-1"><i class="fa fa-check"></i><b>9.2.1</b> Posterior via grid approximation.</a></li>
<li class="chapter" data-level="9.2.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-realistic-model-with-mcmc."><i class="fa fa-check"></i><b>9.2.2</b> A realistic model with MCMC.</a></li>
<li class="chapter" data-level="9.2.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#doing-it-with-jags-brms."><i class="fa fa-check"></i><b>9.2.3</b> Doing it with <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="9.2.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-therapeutic-touch."><i class="fa fa-check"></i><b>9.2.4</b> Example: Therapeutic touch.</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#shrinkage-in-hierarchical-models"><i class="fa fa-check"></i><b>9.3</b> Shrinkage in hierarchical models</a></li>
<li class="chapter" data-level="9.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#speeding-up-jags-brms"><i class="fa fa-check"></i><b>9.4</b> Speeding up <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="9.5" data-path="hierarchical-models.html"><a href="hierarchical-models.html#extending-the-hierarchy-subjects-within-categories"><i class="fa fa-check"></i><b>9.5</b> Extending the hierarchy: Subjects within categories</a><ul>
<li class="chapter" data-level="9.5.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-batting-abilities-by-position."><i class="fa fa-check"></i><b>9.5.1</b> Example: Baseball batting abilities by position.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html"><i class="fa fa-check"></i><b>10</b> Model Comparison and Hierarchical Modeling</a><ul>
<li class="chapter" data-level="10.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#general-formula-and-the-bayes-factor"><i class="fa fa-check"></i><b>10.1</b> General formula and the Bayes factor</a></li>
<li class="chapter" data-level="10.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#example-two-factories-of-coins"><i class="fa fa-check"></i><b>10.2</b> Example: Two factories of coins</a><ul>
<li class="chapter" data-level="10.2.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-formal-analysis."><i class="fa fa-check"></i><b>10.2.1</b> Solution by formal analysis.</a></li>
<li class="chapter" data-level="10.2.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-grid-approximation."><i class="fa fa-check"></i><b>10.2.2</b> Solution by grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-mcmc"><i class="fa fa-check"></i><b>10.3</b> Solution by MCMC</a><ul>
<li class="chapter" data-level="10.3.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#nonhierarchical-mcmc-computation-of-each-models-marginal-likelihood."><i class="fa fa-check"></i><b>10.3.1</b> Nonhierarchical MCMC computation of each model’s marginal likelihood.</a></li>
<li class="chapter" data-level="10.3.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#hierarchical-mcmc-computation-of-relative-model-probability-is-not-available-in-brms-well-cover-information-criteria-instead."><i class="fa fa-check"></i><b>10.3.2</b> Hierarchical MCMC computation <del>of relative model probability</del> is not available in brms: We’ll cover information criteria instead.</a></li>
<li class="chapter" data-level="10.3.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#models-with-different-noise-distributions-in-jags-brms."><i class="fa fa-check"></i><b>10.3.3</b> Models with different “noise” distributions in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#prediction-model-averaging"><i class="fa fa-check"></i><b>10.4</b> Prediction: Model averaging</a></li>
<li class="chapter" data-level="10.5" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#model-complexity-naturally-accounted-for"><i class="fa fa-check"></i><b>10.5</b> Model complexity naturally accounted for</a><ul>
<li class="chapter" data-level="10.5.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#caveats-regarding-nested-model-comparison."><i class="fa fa-check"></i><b>10.5.1</b> Caveats regarding nested model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#extreme-sensitivity-to-the-prior-distribution"><i class="fa fa-check"></i><b>10.6</b> Extreme sensitivity to the prior distribution</a><ul>
<li class="chapter" data-level="10.6.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#priors-of-different-models-should-be-equally-informed."><i class="fa fa-check"></i><b>10.6.1</b> Priors of different models should be equally informed.</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#bonus-theres-danger-ahead"><i class="fa fa-check"></i><b>10.7</b> Bonus: There’s danger ahead</a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>11</b> Null Hypothesis Significance Testing</a><ul>
<li class="chapter" data-level="11.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#paved-with-good-intentions"><i class="fa fa-check"></i><b>11.1</b> Paved with good intentions</a><ul>
<li class="chapter" data-level="11.1.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#definition-of-p-value."><i class="fa fa-check"></i><b>11.1.1</b> Definition of <span class="math inline">\(p\)</span> value.</a></li>
<li class="chapter" data-level="11.1.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-n."><i class="fa fa-check"></i><b>11.1.2</b> With intention to fix <span class="math inline">\(N\)</span>.</a></li>
<li class="chapter" data-level="11.1.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-z."><i class="fa fa-check"></i><b>11.1.3</b> With intention to fix <span class="math inline">\(z\)</span>.</a></li>
<li class="chapter" data-level="11.1.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-duration."><i class="fa fa-check"></i><b>11.1.4</b> With intention to fix duration.</a></li>
<li class="chapter" data-level="11.1.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-make-multiple-tests."><i class="fa fa-check"></i><b>11.1.5</b> With intention to make multiple tests.</a></li>
<li class="chapter" data-level="11.1.6" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#soul-searching."><i class="fa fa-check"></i><b>11.1.6</b> Soul searching.</a></li>
<li class="chapter" data-level="11.1.7" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis."><i class="fa fa-check"></i><b>11.1.7</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#prior-knowledge"><i class="fa fa-check"></i><b>11.2</b> Prior knowledge</a><ul>
<li class="chapter" data-level="11.2.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-analysis."><i class="fa fa-check"></i><b>11.2.1</b> NHST analysis.</a></li>
<li class="chapter" data-level="11.2.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis.-1"><i class="fa fa-check"></i><b>11.2.2</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#confidence-interval-and-highest-density-interval"><i class="fa fa-check"></i><b>11.3</b> Confidence interval and highest density interval</a><ul>
<li class="chapter" data-level="11.3.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#ci-depends-on-intention."><i class="fa fa-check"></i><b>11.3.1</b> CI depends on intention.</a></li>
<li class="chapter" data-level="11.3.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-hdi."><i class="fa fa-check"></i><b>11.3.2</b> Bayesian HDI.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#multiple-comparisons"><i class="fa fa-check"></i><b>11.4</b> Multiple comparisons</a><ul>
<li class="chapter" data-level="11.4.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-correction-for-experiment-wise-error."><i class="fa fa-check"></i><b>11.4.1</b> NHST correction for experiment wise error.</a></li>
<li class="chapter" data-level="11.4.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#just-one-bayesian-posterior-no-matter-how-you-look-at-it."><i class="fa fa-check"></i><b>11.4.2</b> Just one Bayesian posterior no matter how you look at it.</a></li>
<li class="chapter" data-level="11.4.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#how-bayesian-analysis-mitigates-false-alarms."><i class="fa fa-check"></i><b>11.4.3</b> How Bayesian analysis mitigates false alarms.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#what-a-sampling-distribution-is-good-for"><i class="fa fa-check"></i><b>11.5</b> What a sampling distribution is good for</a><ul>
<li class="chapter" data-level="11.5.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#planning-an-experiment."><i class="fa fa-check"></i><b>11.5.1</b> Planning an experiment.</a></li>
<li class="chapter" data-level="11.5.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#exploring-model-predictions-posterior-predictive-check."><i class="fa fa-check"></i><b>11.5.2</b> Exploring model predictions (posterior predictive check).</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><i class="fa fa-check"></i><b>12</b> Bayesian Approaches to Testing a Point (“Null”) Hypothesis</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-estimation-approach"><i class="fa fa-check"></i><b>12.1</b> The estimation approach</a><ul>
<li class="chapter" data-level="12.1.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#region-of-practical-equivalence."><i class="fa fa-check"></i><b>12.1.1</b> Region of practical equivalence.</a></li>
<li class="chapter" data-level="12.1.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#some-examples."><i class="fa fa-check"></i><b>12.1.2</b> Some examples.</a></li>
<li class="chapter" data-level="12.1.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#differences-of-correlated-parameters."><i class="fa fa-check"></i><b>12.1.3</b> Differences of correlated parameters.</a></li>
<li class="chapter" data-level="12.1.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#why-hdi-and-not-equal-tailed-interval"><i class="fa fa-check"></i><b>12.1.4</b> Why HDI and not equal-tailed interval?</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-model-comparison-approach"><i class="fa fa-check"></i><b>12.2</b> The model-comparison approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#is-a-coin-fair-or-not"><i class="fa fa-check"></i><b>12.2.1</b> Is a coin fair or not?</a></li>
<li class="chapter" data-level="12.2.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#bayes-factor-can-accept-null-with-poor-precision."><i class="fa fa-check"></i><b>12.2.2</b> Bayes’ factor can accept null with poor precision.</a></li>
<li class="chapter" data-level="12.2.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#are-different-groups-equal-or-not"><i class="fa fa-check"></i><b>12.2.3</b> Are different groups equal or not?</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#relations-of-parameter-estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.3</b> Relations of parameter estimation and model comparison</a></li>
<li class="chapter" data-level="12.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.4</b> Estimation and model comparison?</a></li>
<li class="chapter" data-level="" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html"><i class="fa fa-check"></i><b>13</b> Goals, Power, and Sample Size</a><ul>
<li class="chapter" data-level="13.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-will-to-power"><i class="fa fa-check"></i><b>13.1</b> The will to power</a><ul>
<li class="chapter" data-level="13.1.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#goals-and-obstacles."><i class="fa fa-check"></i><b>13.1.1</b> Goals and obstacles.</a></li>
<li class="chapter" data-level="13.1.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power."><i class="fa fa-check"></i><b>13.1.2</b> Power.</a></li>
<li class="chapter" data-level="13.1.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sample-size."><i class="fa fa-check"></i><b>13.1.3</b> Sample size.</a></li>
<li class="chapter" data-level="13.1.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#other-expressions-of-goals."><i class="fa fa-check"></i><b>13.1.4</b> Other expressions of goals.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#computing-power-and-sample-size"><i class="fa fa-check"></i><b>13.2</b> Computing power and sample size</a><ul>
<li class="chapter" data-level="13.2.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-to-exclude-a-null-value."><i class="fa fa-check"></i><b>13.2.1</b> When the goal is to exclude a null value.</a></li>
<li class="chapter" data-level="13.2.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#formal-solution-and-implementation-in-r."><i class="fa fa-check"></i><b>13.2.2</b> Formal solution and implementation in R.</a></li>
<li class="chapter" data-level="13.2.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-precision."><i class="fa fa-check"></i><b>13.2.3</b> When the goal is precision.</a></li>
<li class="chapter" data-level="13.2.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#monte-carlo-approximation-of-power."><i class="fa fa-check"></i><b>13.2.4</b> Monte Carlo approximation of power.</a></li>
<li class="chapter" data-level="13.2.5" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-from-idealized-or-actual-data."><i class="fa fa-check"></i><b>13.2.5</b> Power from idealized or actual data.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sequential-testing-and-the-goal-of-precision"><i class="fa fa-check"></i><b>13.3</b> Sequential testing and the goal of precision</a><ul>
<li class="chapter" data-level="13.3.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#examples-ofsequential-tests."><i class="fa fa-check"></i><b>13.3.1</b> Examples ofsequential tests.</a></li>
<li class="chapter" data-level="13.3.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#average-behavior-of-sequential-tests."><i class="fa fa-check"></i><b>13.3.2</b> Average behavior of sequential tests.</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#discussion"><i class="fa fa-check"></i><b>13.4</b> Discussion</a><ul>
<li class="chapter" data-level="13.4.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-and-multiple-comparisons."><i class="fa fa-check"></i><b>13.4.1</b> Power and multiple comparisons.</a></li>
<li class="chapter" data-level="13.4.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-prospective-retrospective-and-replication."><i class="fa fa-check"></i><b>13.4.2</b> Power: prospective, retrospective, and replication.</a></li>
<li class="chapter" data-level="13.4.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-analysis-requires-verisimilitude-of-simulated-data."><i class="fa fa-check"></i><b>13.4.3</b> Power analysis requires verisimilitude of simulated data.</a></li>
<li class="chapter" data-level="13.4.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-importance-of-planning."><i class="fa fa-check"></i><b>13.4.4</b> The importance of planning.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#hmc-sampling"><i class="fa fa-check"></i><b>14.1</b> HMC sampling</a></li>
<li class="chapter" data-level="14.2" data-path="stan.html"><a href="stan.html#installing-stan"><i class="fa fa-check"></i><b>14.2</b> Installing Stan</a></li>
<li class="chapter" data-level="14.3" data-path="stan.html"><a href="stan.html#a-complete-example-1"><i class="fa fa-check"></i><b>14.3</b> A Complete example</a><ul>
<li class="chapter" data-level="14.3.1" data-path="stan.html"><a href="stan.html#reusing-the-compiled-model."><i class="fa fa-check"></i><b>14.3.1</b> Reusing the compiled model.</a></li>
<li class="chapter" data-level="14.3.2" data-path="stan.html"><a href="stan.html#general-structure-of-stan-model-specification."><i class="fa fa-check"></i><b>14.3.2</b> General structure of Stan model specification.</a></li>
<li class="chapter" data-level="14.3.3" data-path="stan.html"><a href="stan.html#think-log-probability-to-think-like-stan."><i class="fa fa-check"></i><b>14.3.3</b> Think log probability to think like Stan.</a></li>
<li class="chapter" data-level="14.3.4" data-path="stan.html"><a href="stan.html#sampling-the-prior-in-stan."><i class="fa fa-check"></i><b>14.3.4</b> Sampling the prior in Stan.</a></li>
<li class="chapter" data-level="14.3.5" data-path="stan.html"><a href="stan.html#simplified-scripts-for-frequently-used-analyses."><i class="fa fa-check"></i><b>14.3.5</b> Simplified scripts for frequently used analyses.</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="stan.html"><a href="stan.html#specify-models-top-down-in-stan"><i class="fa fa-check"></i><b>14.4</b> Specify models top-down in Stan</a></li>
<li class="chapter" data-level="14.5" data-path="stan.html"><a href="stan.html#limitations-and-extras"><i class="fa fa-check"></i><b>14.5</b> Limitations and extras</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>III THE GENERALIZED LINEAR MODEL</b></span></li>
<li class="chapter" data-level="15" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>15</b> Overview of the Generalized Linear Model</a><ul>
<li class="chapter" data-level="15.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#types-of-variables"><i class="fa fa-check"></i><b>15.1</b> Types of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#predictor-and-predicted-variables."><i class="fa fa-check"></i><b>15.1.1</b> Predictor and predicted variables.</a></li>
<li class="chapter" data-level="15.1.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#scale-types-metric-ordinal-nominal-and-count."><i class="fa fa-check"></i><b>15.1.2</b> Scale types: metric, ordinal, nominal, and count.</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-combination-of-predictors"><i class="fa fa-check"></i><b>15.2</b> Linear combination of predictors</a><ul>
<li class="chapter" data-level="15.2.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-function-of-a-single-metric-predictor."><i class="fa fa-check"></i><b>15.2.1</b> Linear function of a single metric predictor.</a></li>
<li class="chapter" data-level="15.2.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#additive-combination-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.2</b> Additive combination of metric predictors.</a></li>
<li class="chapter" data-level="15.2.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nonadditive-interaction-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.3</b> Nonadditive interaction of metric predictors.</a></li>
<li class="chapter" data-level="15.2.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nominal-predictors."><i class="fa fa-check"></i><b>15.2.4</b> Nominal predictors.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linking-from-combined-predictors-to-noisy-predicted-data"><i class="fa fa-check"></i><b>15.3</b> Linking from combined predictors to noisy predicted data</a><ul>
<li class="chapter" data-level="15.3.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predictors-to-predicted-central-tendency."><i class="fa fa-check"></i><b>15.3.1</b> From predictors to predicted central tendency.</a></li>
<li class="chapter" data-level="15.3.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predicted-central-tendency-to-noisy-data."><i class="fa fa-check"></i><b>15.3.2</b> From predicted central tendency to noisy data.</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#formal-expression-of-the-glm"><i class="fa fa-check"></i><b>15.4</b> Formal expression of the GLM</a><ul>
<li class="chapter" data-level="15.4.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#cases-of-the-glm."><i class="fa fa-check"></i><b>15.4.1</b> Cases of the GLM.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html"><i class="fa fa-check"></i><b>16</b> Metric-Predicted Variable on One or Two Groups</a><ul>
<li class="chapter" data-level="16.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#estimating-the-mean-and-standard-deviation-of-a-normal-distribution"><i class="fa fa-check"></i><b>16.1</b> Estimating the mean and standard deviation of a normal distribution</a><ul>
<li class="chapter" data-level="16.1.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#solution-by-mathematical-analysis-heads-up-on-precision."><i class="fa fa-check"></i><b>16.1.1</b> <del>Solution by mathematical analysis</del> Heads up on precision.</a></li>
<li class="chapter" data-level="16.1.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#approximation-by-mcmc-in-jags-hmc-in-brms."><i class="fa fa-check"></i><b>16.1.2</b> Approximation by <del>MCMC in JAGS</del> HMC in brms.</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#outliers-and-robust-estimation-the-t-distribution"><i class="fa fa-check"></i><b>16.2</b> Outliers and robust estimation: The <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="16.2.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-jags-brms."><i class="fa fa-check"></i><b>16.2.1</b> Using the <span class="math inline">\(t\)</span> distribution in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="16.2.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-stan."><i class="fa fa-check"></i><b>16.2.2</b> Using the <span class="math inline">\(t\)</span> distribution in Stan.</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#two-groups"><i class="fa fa-check"></i><b>16.3</b> Two groups</a><ul>
<li class="chapter" data-level="16.3.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#analysis-by-nhst."><i class="fa fa-check"></i><b>16.3.1</b> Analysis by NHST.</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#other-noise-distributions-and-transforming-data"><i class="fa fa-check"></i><b>16.4</b> Other noise distributions and transforming data</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#reference-15"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#session-info-15"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html"><i class="fa fa-check"></i><b>17</b> Metric Predicted Variable with One Metric Predictor</a><ul>
<li class="chapter" data-level="17.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#simple-linear-regression"><i class="fa fa-check"></i><b>17.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="17.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression"><i class="fa fa-check"></i><b>17.2</b> Robust linear regression</a><ul>
<li class="chapter" data-level="17.2.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-jags-brms."><i class="fa fa-check"></i><b>17.2.1</b> Robust linear regression in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.2.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-stan."><i class="fa fa-check"></i><b>17.2.2</b> Robust linear regression in Stan.</a></li>
<li class="chapter" data-level="17.2.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#stan-or-jags"><i class="fa fa-check"></i><b>17.2.3</b> Stan or JAGS?</a></li>
<li class="chapter" data-level="17.2.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#interpreting-the-posterior-distribution."><i class="fa fa-check"></i><b>17.2.4</b> Interpreting the posterior distribution.</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#hierarchical-regression-on-individuals-within-groups"><i class="fa fa-check"></i><b>17.3</b> Hierarchical regression on individuals within groups</a><ul>
<li class="chapter" data-level="17.3.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>17.3.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.3.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-posterior-distribution-shrinkage-and-prediction."><i class="fa fa-check"></i><b>17.3.2</b> The posterior distribution: Shrinkage and prediction.</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#quadratic-trend-and-weighted-data"><i class="fa fa-check"></i><b>17.4</b> Quadratic trend and weighted data</a><ul>
<li class="chapter" data-level="17.4.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#results-and-interpretation."><i class="fa fa-check"></i><b>17.4.1</b> Results and interpretation.</a></li>
<li class="chapter" data-level="17.4.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#further-extensions."><i class="fa fa-check"></i><b>17.4.2</b> Further extensions.</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#procedure-and-perils-for-expanding-a-model"><i class="fa fa-check"></i><b>17.5</b> Procedure and perils for expanding a model</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#reference-16"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#session-info-16"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Metric Predicted Variable with Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiple-linear-regression"><i class="fa fa-check"></i><b>18.1</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="18.1.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-perils-of-correlated-predictors."><i class="fa fa-check"></i><b>18.1.1</b> The perils of correlated predictors.</a></li>
<li class="chapter" data-level="18.1.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-model-and-implementation."><i class="fa fa-check"></i><b>18.1.2</b> The model and implementation.</a></li>
<li class="chapter" data-level="18.1.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-posterior-distribution."><i class="fa fa-check"></i><b>18.1.3</b> The posterior distribution.</a></li>
<li class="chapter" data-level="18.1.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#redundant-predictors."><i class="fa fa-check"></i><b>18.1.4</b> Redundant predictors.</a></li>
<li class="chapter" data-level="18.1.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#informative-priors-sparse-data-and-correlated-predictors."><i class="fa fa-check"></i><b>18.1.5</b> Informative priors, sparse data, and correlated predictors.</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiplicative-interaction-of-metric-predictors"><i class="fa fa-check"></i><b>18.2</b> Multiplicative interaction of metric predictors</a><ul>
<li class="chapter" data-level="18.2.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#an-example."><i class="fa fa-check"></i><b>18.2.1</b> An example.</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#shrinkage-of-regression-coefficients"><i class="fa fa-check"></i><b>18.3</b> Shrinkage of regression coefficients</a></li>
<li class="chapter" data-level="18.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection"><i class="fa fa-check"></i><b>18.4</b> Variable selection</a><ul>
<li class="chapter" data-level="18.4.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#inclusion-probability-is-strongly-affected-by-vagueness-of-prior."><i class="fa fa-check"></i><b>18.4.1</b> Inclusion probability is strongly affected by vagueness of prior.</a></li>
<li class="chapter" data-level="18.4.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection-with-hierarchical-shrinkage."><i class="fa fa-check"></i><b>18.4.2</b> Variable selection with hierarchical shrinkage.</a></li>
<li class="chapter" data-level="18.4.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#what-to-report-and-what-to-conclude."><i class="fa fa-check"></i><b>18.4.3</b> What to report and what to conclude.</a></li>
<li class="chapter" data-level="18.4.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-computational-methods."><i class="fa fa-check"></i><b>18.4.4</b> Caution: Computational methods.</a></li>
<li class="chapter" data-level="18.4.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-interaction-variables."><i class="fa fa-check"></i><b>18.4.5</b> Caution: Interaction variables.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#reference-17"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#session-info-17"><i class="fa fa-check"></i>Session info</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#footnote"><i class="fa fa-check"></i>Footnote</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html"><i class="fa fa-check"></i><b>19</b> Metric Predicted Variable with One Nominal Predictor</a><ul>
<li class="chapter" data-level="19.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#describing-multiple-groups-of-metric-data"><i class="fa fa-check"></i><b>19.1</b> Describing multiple groups of metric data</a></li>
<li class="chapter" data-level="19.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#traditional-analysis-of-variance"><i class="fa fa-check"></i><b>19.2</b> Traditional analysis of variance</a></li>
<li class="chapter" data-level="19.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#hierarchical-bayesian-approach"><i class="fa fa-check"></i><b>19.3</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="19.3.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#implementation-in-jags-brms."><i class="fa fa-check"></i><b>19.3.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="19.3.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-and-death."><i class="fa fa-check"></i><b>19.3.2</b> Example: Sex and death.</a></li>
<li class="chapter" data-level="19.3.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#contrasts."><i class="fa fa-check"></i><b>19.3.3</b> Contrasts.</a></li>
<li class="chapter" data-level="19.3.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#multiple-comparisons-and-shrinkage."><i class="fa fa-check"></i><b>19.3.4</b> Multiple comparisons and shrinkage.</a></li>
<li class="chapter" data-level="19.3.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#the-two-group-case."><i class="fa fa-check"></i><b>19.3.5</b> The two-group case.</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#including-a-metric-predictor"><i class="fa fa-check"></i><b>19.4</b> Including a metric predictor</a><ul>
<li class="chapter" data-level="19.4.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-death-and-size."><i class="fa fa-check"></i><b>19.4.1</b> Example: Sex, death, and size.</a></li>
<li class="chapter" data-level="19.4.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#analogous-to-traditional-ancova."><i class="fa fa-check"></i><b>19.4.2</b> Analogous to traditional ANCOVA.</a></li>
<li class="chapter" data-level="19.4.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#relation-to-hierarchical-linear-regression."><i class="fa fa-check"></i><b>19.4.3</b> Relation to hierarchical linear regression.</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#heterogeneous-variances-and-robustness-against-outliers"><i class="fa fa-check"></i><b>19.5</b> Heterogeneous variances and robustness against outliers</a><ul>
<li class="chapter" data-level="19.5.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-contrast-of-means-with-different-variances."><i class="fa fa-check"></i><b>19.5.1</b> Example: Contrast of means with different variances.</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#exercises-walk-out-an-effect-size"><i class="fa fa-check"></i><b>19.6</b> <del>Exercises</del> Walk out an effect size</a><ul>
<li class="chapter" data-level="19.6.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#populations-and-samples."><i class="fa fa-check"></i><b>19.6.1</b> Populations and samples.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#reference-18"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#session-info-18"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html"><i class="fa fa-check"></i><b>20</b> Metric Predicted Variable with Multiple Nominal Predictors</a><ul>
<li class="chapter" data-level="20.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#describing-groups-of-metric-data-with-multiple-nominal-predictors"><i class="fa fa-check"></i><b>20.1</b> Describing groups of metric data with multiple nominal predictors</a><ul>
<li class="chapter" data-level="20.1.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction."><i class="fa fa-check"></i><b>20.1.1</b> Interaction.</a></li>
<li class="chapter" data-level="20.1.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#traditional-anova."><i class="fa fa-check"></i><b>20.1.2</b> Traditional ANOVA.</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#hierarchical-bayesian-approach-1"><i class="fa fa-check"></i><b>20.2</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="20.2.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>20.2.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="20.2.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#example-its-only-money."><i class="fa fa-check"></i><b>20.2.2</b> Example: It’s only money.</a></li>
<li class="chapter" data-level="20.2.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#main-effect-contrasts."><i class="fa fa-check"></i><b>20.2.3</b> Main effect contrasts.</a></li>
<li class="chapter" data-level="20.2.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction-contrasts-and-simple-effects."><i class="fa fa-check"></i><b>20.2.4</b> Interaction contrasts and simple effects.</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#rescaling-can-change-interactions-homogeneity-and-normality"><i class="fa fa-check"></i><b>20.3</b> Rescaling can change interactions, homogeneity, and normality</a></li>
<li class="chapter" data-level="20.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#heterogeneous-variances-and-robustness-against-outliers-1"><i class="fa fa-check"></i><b>20.4</b> Heterogeneous variances and robustness against outliers</a></li>
<li class="chapter" data-level="20.5" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#within-subject-designs"><i class="fa fa-check"></i><b>20.5</b> Within-subject designs</a><ul>
<li class="chapter" data-level="20.5.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#why-use-a-within-subject-design-and-why-not"><i class="fa fa-check"></i><b>20.5.1</b> Why use a within-subject design? And why not?</a></li>
<li class="chapter" data-level="20.5.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#split-plot-design."><i class="fa fa-check"></i><b>20.5.2</b> Split-plot design.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#reference-19"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#session-info-19"><i class="fa fa-check"></i>Session info</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#footnote-1"><i class="fa fa-check"></i>Footnote</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html"><i class="fa fa-check"></i><b>21</b> Dichotomous Predicted Variable</a><ul>
<li class="chapter" data-level="21.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-metric-predictors"><i class="fa fa-check"></i><b>21.1</b> Multiple metric predictors</a><ul>
<li class="chapter" data-level="21.1.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#the-model-and-implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>21.1.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="21.1.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#example-height-weight-and-gender."><i class="fa fa-check"></i><b>21.1.2</b> Example: Height, weight, and gender.</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interpreting-the-regression-coefficients"><i class="fa fa-check"></i><b>21.2</b> Interpreting the regression coefficients</a><ul>
<li class="chapter" data-level="21.2.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#log-odds."><i class="fa fa-check"></i><b>21.2.1</b> Log odds.</a></li>
<li class="chapter" data-level="21.2.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#when-there-are-few-1s-or-0s-in-the-data."><i class="fa fa-check"></i><b>21.2.2</b> When there are few 1’s or 0’s in the data.</a></li>
<li class="chapter" data-level="21.2.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#correlated-predictors."><i class="fa fa-check"></i><b>21.2.3</b> Correlated predictors.</a></li>
<li class="chapter" data-level="21.2.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interaction-of-metric-predictors."><i class="fa fa-check"></i><b>21.2.4</b> Interaction of metric predictors.</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#robust-logistic-regression"><i class="fa fa-check"></i><b>21.3</b> Robust logistic regression</a></li>
<li class="chapter" data-level="21.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#nominal-predictors"><i class="fa fa-check"></i><b>21.4</b> Nominal predictors</a><ul>
<li class="chapter" data-level="21.4.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#single-group."><i class="fa fa-check"></i><b>21.4.1</b> Single group.</a></li>
<li class="chapter" data-level="21.4.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-groups."><i class="fa fa-check"></i><b>21.4.2</b> Multiple groups.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#reference-20"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#session-info-20"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html"><i class="fa fa-check"></i><b>22</b> Nominal Predicted Variable</a><ul>
<li class="chapter" data-level="22.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-regression"><i class="fa fa-check"></i><b>22.1</b> Softmax regression</a><ul>
<li class="chapter" data-level="22.1.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-reduces-to-logistic-for-two-outcomes."><i class="fa fa-check"></i><b>22.1.1</b> Softmax reduces to logistic for two outcomes.</a></li>
<li class="chapter" data-level="22.1.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#independence-from-irrelevant-attributes."><i class="fa fa-check"></i><b>22.1.2</b> Independence from irrelevant attributes.</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-regression"><i class="fa fa-check"></i><b>22.2</b> Conditional logistic regression</a></li>
<li class="chapter" data-level="22.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#implementation-in-jags-brms"><i class="fa fa-check"></i><b>22.3</b> Implementation in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="22.3.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-model."><i class="fa fa-check"></i><b>22.3.1</b> Softmax model.</a></li>
<li class="chapter" data-level="22.3.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-model."><i class="fa fa-check"></i><b>22.3.2</b> Conditional logistic model.</a></li>
<li class="chapter" data-level="22.3.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#results-interpreting-the-regression-coefficients."><i class="fa fa-check"></i><b>22.3.3</b> Results: Interpreting the regression coefficients.</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#generalizations-and-variations-of-the-models"><i class="fa fa-check"></i><b>22.4</b> Generalizations and variations of the models</a></li>
<li class="chapter" data-level="" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#reference-21"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#session-info-21"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html"><i class="fa fa-check"></i><b>23</b> Ordinal Predicted Variable</a><ul>
<li class="chapter" data-level="23.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#modeling-ordinal-data-with-an-underlying-metric-variable"><i class="fa fa-check"></i><b>23.1</b> Modeling ordinal data with an underlying metric variable</a></li>
<li class="chapter" data-level="23.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-a-single-group"><i class="fa fa-check"></i><b>23.2</b> The case of a single group</a><ul>
<li class="chapter" data-level="23.2.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-3"><i class="fa fa-check"></i><b>23.2.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.2.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-bayesian-estimation-recovers-true-parameter-values."><i class="fa fa-check"></i><b>23.2.2</b> Examples: Bayesian estimation recovers true parameter values.</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-two-groups"><i class="fa fa-check"></i><b>23.3</b> The case of two groups</a><ul>
<li class="chapter" data-level="23.3.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-4"><i class="fa fa-check"></i><b>23.3.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.3.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-not-funny."><i class="fa fa-check"></i><b>23.3.2</b> Examples: Not funny.</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-metric-predictors"><i class="fa fa-check"></i><b>23.4</b> The Case of metric predictors</a><ul>
<li class="chapter" data-level="23.4.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-5"><i class="fa fa-check"></i><b>23.4.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="23.4.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-happiness-and-money."><i class="fa fa-check"></i><b>23.4.2</b> Example: Happiness and money.</a></li>
<li class="chapter" data-level="23.4.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-moviesthey-dont-make-em-like-they-used-to."><i class="fa fa-check"></i><b>23.4.3</b> Example: Movies–They don’t make ’em like they used to.</a></li>
<li class="chapter" data-level="23.4.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#why-are-some-thresholds-outside-the-data"><i class="fa fa-check"></i><b>23.4.4</b> Why are some thresholds outside the data?</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#posterior-prediction"><i class="fa fa-check"></i><b>23.5</b> Posterior prediction</a></li>
<li class="chapter" data-level="23.6" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#generalizations-and-extensions"><i class="fa fa-check"></i><b>23.6</b> Generalizations and extensions</a></li>
<li class="chapter" data-level="" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#reference-22"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#session-info-22"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html"><i class="fa fa-check"></i><b>24</b> Count Predicted Variable</a><ul>
<li class="chapter" data-level="24.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-exponential-model"><i class="fa fa-check"></i><b>24.1</b> Poisson exponential model</a><ul>
<li class="chapter" data-level="24.1.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#data-structure."><i class="fa fa-check"></i><b>24.1.1</b> Data structure.</a></li>
<li class="chapter" data-level="24.1.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#exponential-link-function."><i class="fa fa-check"></i><b>24.1.2</b> Exponential link function.</a></li>
<li class="chapter" data-level="24.1.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-noise-distribution."><i class="fa fa-check"></i><b>24.1.3</b> Poisson noise distribution.</a></li>
<li class="chapter" data-level="24.1.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#the-complete-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>24.1.4</b> The complete model and implementation in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-hair-eye-go-again"><i class="fa fa-check"></i><b>24.2</b> Example: Hair eye go again</a></li>
<li class="chapter" data-level="24.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-interaction-contrasts-shrinkage-and-omnibus-test"><i class="fa fa-check"></i><b>24.3</b> Example: Interaction contrasts, shrinkage, and omnibus test</a></li>
<li class="chapter" data-level="24.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#log-linear-models-for-contingency-tables-bonus-alternative-parameterization"><i class="fa fa-check"></i><b>24.4</b> <del>Log-linear models for contingency tables</del> Bonus: Alternative parameterization</a></li>
<li class="chapter" data-level="" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#reference-23"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#session-info-23"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html"><i class="fa fa-check"></i><b>25</b> Tools in the Trunk</a><ul>
<li class="chapter" data-level="25.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#reporting-a-bayesian-analysis"><i class="fa fa-check"></i><b>25.1</b> Reporting a Bayesian analysis</a><ul>
<li class="chapter" data-level="25.1.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#essential-points."><i class="fa fa-check"></i><b>25.1.1</b> Essential points.</a></li>
<li class="chapter" data-level="25.1.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#optional-points."><i class="fa fa-check"></i><b>25.1.2</b> Optional points.</a></li>
<li class="chapter" data-level="25.1.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#helpful-points."><i class="fa fa-check"></i><b>25.1.3</b> Helpful points.</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#functions-for-computing-highest-density-intervals"><i class="fa fa-check"></i><b>25.2</b> Functions for computing highest density intervals</a><ul>
<li class="chapter" data-level="25.2.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-grid-approximation."><i class="fa fa-check"></i><b>25.2.1</b> R code for computing HDI of a grid approximation.</a></li>
<li class="chapter" data-level="25.2.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#hdi-of-unimodal-distribution-is-shortest-interval."><i class="fa fa-check"></i><b>25.2.2</b> HDI of unimodal distribution is shortest interval.</a></li>
<li class="chapter" data-level="25.2.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-mcmc-sample."><i class="fa fa-check"></i><b>25.2.3</b> R code for computing HDI of a MCMC sample.</a></li>
<li class="chapter" data-level="25.2.4" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-function."><i class="fa fa-check"></i><b>25.2.4</b> R code for computing HDI of a function.</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#reparameterization"><i class="fa fa-check"></i><b>25.3</b> Reparameterization</a></li>
<li class="chapter" data-level="25.4" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#censored-data-in-jags-brms"><i class="fa fa-check"></i><b>25.4</b> Censored Data in <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="25.5" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#what-next"><i class="fa fa-check"></i><b>25.5</b> What Next?</a></li>
<li class="chapter" data-level="" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#reference-24"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#session-info-24"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Doing Bayesian Data Analysis</em> in brms and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-comparison-and-hierarchical-modeling" class="section level1">
<h1><span class="header-section-number">10</span> Model Comparison and Hierarchical Modeling</h1>
<blockquote>
<p>There are situations in which different models compete to describe the same set of data…</p>
<p>…Bayesian inference is reallocation of credibility over possibilities. In model comparison, the focal possibilities are the models, and Bayesian model comparison reallocates credibility across the models, given the data. In this chapter, we explore examples and methods of Bayesian inference about the relative credibilities of models. (pp. 265–266)</p>
</blockquote>
<p>In the text, the emphasis is on the Bayes Factor paradigm. While we will discuss that, we will also present the alternatives available with information criteria, model averaging, and model stacking.</p>
<div id="general-formula-and-the-bayes-factor" class="section level2">
<h2><span class="header-section-number">10.1</span> General formula and the Bayes factor</h2>
<p>So far we have spoken of</p>
<ul>
<li>the data, denoted by <span class="math inline">\(D\)</span> or <span class="math inline">\(y\)</span>;</li>
<li>the model parameters, generically denoted by <span class="math inline">\(\theta\)</span>;</li>
<li>the likelihood function, denoted by <span class="math inline">\(p(D | \theta)\)</span>; and</li>
<li>the prior distribution, denoted by <span class="math inline">\(p(\theta)\)</span>.</li>
</ul>
<p>Now we add to that <span class="math inline">\(m\)</span>, which is a model index with <span class="math inline">\(m = 1\)</span> standing for the first model, <span class="math inline">\(m = 2\)</span> standing for the second model, and so on. So when we have more than one model in play, we might refer to the likelihood as <span class="math inline">\(p_m(y | \theta_m, m)\)</span> and the prior as <span class="math inline">\(p_m(\theta_m | m)\)</span>. It’s also the case, then, that each model can be given a prior probability <span class="math inline">\(p(m)\)</span>.</p>
<p>“The Bayes factor (BF) is the ratio of the probabilities of the data in models 1 and 2” (p. 268).</p>
<p>This can be expressed simply as</p>
<p><span class="math display">\[\text{BF} = \frac{p(D | m = 1)}{p(D | m = 2)}.\]</span></p>
<p>Kruschke further explained that</p>
<blockquote>
<p>one convention for converting the magnitude of the BF to a discrete decision about the models is that there is “substantial” evidence for model <span class="math inline">\(m = 1\)</span> when the BF exceeds 3.0 and, equivalently, “substantial” evidence for model <span class="math inline">\(m = 2\)</span> when the BF is less than 1/3 (<a href="https://global.oup.com/academic/product/theory-of-probability-9780198503682?cc=us&amp;lang=en&amp;">Jeffreys, 1961</a>; <a href="https://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf">Kass &amp; Raftery, 1995</a>; <a href="https://pdfs.semanticscholar.org/1874/4e6c84087ccc20bc0f6db28020bc48c81b4a.pdf">Wetzels et al., 2011</a>).</p>
</blockquote>
<p>However, as with <span class="math inline">\(p\)</span>-values, effect sizes, and so on, BF values exist within continua and might should be evaluated in terms of degree more so than as ordered kinds.</p>
</div>
<div id="example-two-factories-of-coins" class="section level2">
<h2><span class="header-section-number">10.2</span> Example: Two factories of coins</h2>
<p>Kruschke considered the coin bias of two factories, each described by the beta distribution. We can organize how to derive the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters from <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\kappa\)</span> with a tibble.</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb738-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb738-2" data-line-number="2"></a>
<a class="sourceLine" id="cb738-3" data-line-number="3">d &lt;-</a>
<a class="sourceLine" id="cb738-4" data-line-number="4"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">factory =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb738-5" data-line-number="5">         <span class="dt">omega   =</span> <span class="kw">c</span>(.<span class="dv">25</span>, <span class="fl">.75</span>),</a>
<a class="sourceLine" id="cb738-6" data-line-number="6">         <span class="dt">kappa   =</span> <span class="dv">12</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb738-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">alpha =</span>      omega  <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb738-8" data-line-number="8">         <span class="dt">beta  =</span> (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb738-9" data-line-number="9"></a>
<a class="sourceLine" id="cb738-10" data-line-number="10">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb738-11" data-line-number="11"><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">factory</th>
<th align="right">omega</th>
<th align="right">kappa</th>
<th align="right">alpha</th>
<th align="right">beta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.25</td>
<td align="right">12</td>
<td align="right">3.5</td>
<td align="right">8.5</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.75</td>
<td align="right">12</td>
<td align="right">8.5</td>
<td align="right">3.5</td>
</tr>
</tbody>
</table>
<p>Thus given <span class="math inline">\(\omega_1 = .25\)</span>, <span class="math inline">\(\omega_2 = .75\)</span> and <span class="math inline">\(\kappa = 12\)</span>, we can describe the bias of the two coin factories as <span class="math inline">\(\operatorname{beta} (\theta_{[m = 1]} | 3.5, 8.5)\)</span> and <span class="math inline">\(\operatorname{beta} (\theta_{[m = 2]} | 8.5, 3.5)\)</span>. With a little wrangling, we canuse our <code>d</code> tibble to make the densities of Figure 10.2.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb739-1" data-line-number="1">length &lt;-<span class="st"> </span><span class="dv">101</span></a>
<a class="sourceLine" id="cb739-2" data-line-number="2"></a>
<a class="sourceLine" id="cb739-3" data-line-number="3">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb739-4" data-line-number="4"><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(factory, alpha, beta),</a>
<a class="sourceLine" id="cb739-5" data-line-number="5">         <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb739-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">label =</span> <span class="kw">str_c</span>(<span class="st">&quot;factory &quot;</span>, factory)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb739-7" data-line-number="7"><span class="st">  </span></a>
<a class="sourceLine" id="cb739-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, </a>
<a class="sourceLine" id="cb739-9" data-line-number="9">             <span class="dt">ymin =</span> <span class="dv">0</span>, </a>
<a class="sourceLine" id="cb739-10" data-line-number="10">             <span class="dt">ymax =</span> <span class="kw">dbeta</span>(<span class="dt">x =</span> theta, <span class="dt">shape1 =</span> alpha, <span class="dt">shape2 =</span> beta))) <span class="op">+</span></a>
<a class="sourceLine" id="cb739-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb739-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb739-13" data-line-number="13"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span></a>
<a class="sourceLine" id="cb739-14" data-line-number="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb739-15" data-line-number="15"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>label)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /></p>
<p>We might recreate the top panel with <code>geom_col()</code>.</p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb740-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">Model =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;2&quot;</span>),</a>
<a class="sourceLine" id="cb740-2" data-line-number="2">       <span class="dt">y     =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb740-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb740-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Model, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb740-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">width =</span> <span class="fl">.75</span>, <span class="dt">fill =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb740-6" data-line-number="6"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb740-7" data-line-number="7"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(P)[<span class="kw">italic</span>(m)]))) <span class="op">+</span></a>
<a class="sourceLine" id="cb740-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb740-9" data-line-number="9">        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /></p>
<p>Consider the Bernoulli bar plots in the bottom panels of Figure 10.2. The heights of the bars are arbitrary and just intended to give a sense of the Bernoulli distribution. If we wanted the heights to correspond to the Beta distributions above them, we might do so like this.</p>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb741-1" data-line-number="1"><span class="kw">crossing</span>(<span class="dt">factory =</span> <span class="kw">str_c</span>(<span class="st">&quot;factory &quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>),</a>
<a class="sourceLine" id="cb741-2" data-line-number="2">         <span class="dt">flip    =</span> <span class="kw">factor</span>(<span class="kw">c</span>(<span class="st">&quot;tails&quot;</span>, <span class="st">&quot;heads&quot;</span>), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;tails&quot;</span>, <span class="st">&quot;heads&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb741-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prob =</span> <span class="kw">c</span>(.<span class="dv">75</span>, <span class="fl">.25</span>, <span class="fl">.25</span>, <span class="fl">.75</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb741-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb741-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> flip, <span class="dt">y =</span> prob)) <span class="op">+</span></a>
<a class="sourceLine" id="cb741-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">width =</span> <span class="fl">.75</span>, <span class="dt">fill =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb741-7" data-line-number="7"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb741-8" data-line-number="8"><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb741-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb741-10" data-line-number="10">        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb741-11" data-line-number="11"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>factory)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /></p>
<p>But now</p>
<blockquote>
<p>suppose we flip the coin nine times and get six heads. Given those data, what are the posterior probabilities of the coin coming from the head-biased or tail-biased factories? We will pursue the answer three ways: via formal analysis, grid approximation, and MCMC. (p. 270)</p>
</blockquote>
<div id="solution-by-formal-analysis." class="section level3">
<h3><span class="header-section-number">10.2.1</span> Solution by formal analysis.</h3>
<p>Here we rehearse if we have <span class="math inline">\(\operatorname{beta} (\theta, a, b)\)</span> prior for <span class="math inline">\(\theta\)</span> of the Bernoulli likelihood function, then the analytic solution for the posterior is <span class="math inline">\(\operatorname{beta} (\theta | z + a, N – z + b)\)</span>. Within this paradigm, if you would like to compute <span class="math inline">\(p(D | m)\)</span>, don’t use the following function. If suffers from <a href="https://en.wikipedia.org/wiki/Arithmetic_underflow">underflow</a> with large values.</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb742-1" data-line-number="1">p_d &lt;-<span class="st"> </span><span class="cf">function</span>(z, n, a, b) { </a>
<a class="sourceLine" id="cb742-2" data-line-number="2">  <span class="kw">beta</span>(z <span class="op">+</span><span class="st"> </span>a, n <span class="op">-</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span>b) <span class="op">/</span><span class="st"> </span><span class="kw">beta</span>(a, b) </a>
<a class="sourceLine" id="cb742-3" data-line-number="3">}</a></code></pre></div>
<p>This version is more robust.</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb743-1" data-line-number="1">p_d &lt;-<span class="st"> </span><span class="cf">function</span>(z, n, a, b) { </a>
<a class="sourceLine" id="cb743-2" data-line-number="2">  <span class="kw">exp</span>(<span class="kw">lbeta</span>(z <span class="op">+</span><span class="st"> </span>a, n <span class="op">-</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span>b) <span class="op">-</span><span class="st"> </span><span class="kw">lbeta</span>(a, b)) </a>
<a class="sourceLine" id="cb743-3" data-line-number="3">}</a></code></pre></div>
<p>You’d use it like this to compute <span class="math inline">\(p(D|m_1)\)</span>.</p>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb744-1" data-line-number="1"><span class="kw">p_d</span>(<span class="dt">z =</span> <span class="dv">6</span>, <span class="dt">n =</span> <span class="dv">9</span>, <span class="dt">a =</span> <span class="fl">3.5</span>, <span class="dt">b =</span> <span class="fl">8.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.0004993439</code></pre>
<p>So to compute our BF, <span class="math inline">\(\frac{p(D|m_1)}{p(D|m_2)}\)</span>, you might use the <code>p_d()</code> function like this.</p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb746-1" data-line-number="1">p_d_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">p_d</span>(<span class="dt">z =</span> <span class="dv">6</span>, <span class="dt">n =</span> <span class="dv">9</span>, <span class="dt">a =</span> <span class="fl">3.5</span>, <span class="dt">b =</span> <span class="fl">8.5</span>)</a>
<a class="sourceLine" id="cb746-2" data-line-number="2">p_d_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">p_d</span>(<span class="dt">z =</span> <span class="dv">6</span>, <span class="dt">n =</span> <span class="dv">9</span>, <span class="dt">a =</span> <span class="fl">8.5</span>, <span class="dt">b =</span> <span class="fl">3.5</span>)</a>
<a class="sourceLine" id="cb746-3" data-line-number="3"></a>
<a class="sourceLine" id="cb746-4" data-line-number="4">p_d_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>p_d_<span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 0.2135266</code></pre>
<p>And if we computed the BF the other way, it’d look like this.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb748-1" data-line-number="1">p_d_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>p_d_<span class="dv">1</span></a></code></pre></div>
<pre><code>## [1] 4.683258</code></pre>
<p>Since the BF itself is only <span class="math inline">\(\text{BF} = \frac{p(D | m = 1)}{p(D | m = 2)}\)</span>, we’d need to bring in the priors for the models themselves to get the posterior probabilities, which follows the form</p>
<p><span class="math display">\[\frac{p(m = 1 | D)}{p(m = 2 | D)} = \Bigg (\frac{p(D | m = 1)}{p(D | m = 2)} \Bigg ) \Bigg ( \frac{p(m = 1)}{p(m = 2)} \Bigg).\]</span></p>
<p>If for both our models <span class="math inline">\(p(m) = .5\)</span>, then the BF is</p>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb750-1" data-line-number="1">(p_d_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="fl">.5</span>) <span class="op">/</span><span class="st"> </span>(p_d_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="fl">.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.2135266</code></pre>
<p>As Kruschke pointed out, because we’re working in the probability metric, the sum of <span class="math inline">\(p(m = 1 | D )\)</span> and <span class="math inline">\(p(m = 2 | D )\)</span> must be 1. By simple algebra then,</p>
<p><span class="math display">\[p(m = 2 | D ) = 1 - p(m = 1 | D ).\]</span></p>
<p>Therefore, it’s also the case that</p>
<p><span class="math display">\[\frac{p(m = 1 | D)}{1 - p(m = 1 | D)} = 0.2135266.\]</span></p>
<p>Thus, 0.2135266 is in an odds metric. If you want to convert odds to a probability, you follow the formula</p>
<p><span class="math display">\[\text{odds} = \frac{\text{probability}}{1 - \text{probability}}.\]</span></p>
<p>And with more algegraic manipulation, you can solve for the probability.</p>
<p><span class="math display">\[\begin{align*}
\text{odds} &amp; =  \frac{\text{probability}}{1 - \text{probability}} \\
\text{odds} - \text{odds} \cdot \text{probability} &amp; =  \text{probability} \\
\text{odds} &amp; =  \text{probability} + \text{odds} \cdot \text{probability} \\
\text{odds} &amp; =  \text{probability} (1 + \text{odds}) \\
\frac{\text{odds}}{1 + \text{odds}} &amp; =  \text{probability}
\end{align*}\]</span></p>
<p>Thus, the posterior probability for <span class="math inline">\(m = 1\)</span> is</p>
<p><span class="math display">\[p(m = 1 | D) = \frac{0.2135266}{1 + 0.2135266}.\]</span></p>
<p>We can express that in code like so.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb752-1" data-line-number="1">odds &lt;-<span class="st"> </span>(p_d_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="fl">.5</span>) <span class="op">/</span><span class="st"> </span>(p_d_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="fl">.5</span>)</a>
<a class="sourceLine" id="cb752-2" data-line-number="2"></a>
<a class="sourceLine" id="cb752-3" data-line-number="3">odds <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>odds)</a></code></pre></div>
<pre><code>## [1] 0.1759554</code></pre>
<p>Relative to <span class="math inline">\(m = 2\)</span>, our posterior probability for <span class="math inline">\(m = 1\)</span> is about .18. Therefore the posterior probability of <span class="math inline">\(m = 2\)</span> is 1 minus that.</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb754-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(odds <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>odds))</a></code></pre></div>
<pre><code>## [1] 0.8240446</code></pre>
<p>Given the data, the two models and the prior assumption they were equally credible, we conclude <span class="math inline">\(m = 2\)</span> is .82 probable.</p>
</div>
<div id="solution-by-grid-approximation." class="section level3">
<h3><span class="header-section-number">10.2.2</span> Solution by grid approximation.</h3>
<p>We won’t be able to make the wireframe plots on the left of Figure 10.3, but we can do some of the others. Here’s the upper right panel.</p>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb756-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">omega =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb756-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">m_p =</span> <span class="kw">ifelse</span>(omega <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(.<span class="dv">25</span>, <span class="fl">.75</span>), <span class="dv">15</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb756-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb756-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> omega, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> m_p)) <span class="op">+</span></a>
<a class="sourceLine" id="cb756-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb756-6" data-line-number="6"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Remember, the scale on the x is arbitrary.&quot;</span>,</a>
<a class="sourceLine" id="cb756-7" data-line-number="7">       <span class="dt">x =</span> <span class="kw">expression</span>(omega),</a>
<a class="sourceLine" id="cb756-8" data-line-number="8">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(omega))) <span class="op">+</span></a>
<a class="sourceLine" id="cb756-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_flip</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb756-10" data-line-number="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /></p>
<p>Building on that, here’s the upper middle panel of the “two [prior] dorsal fins” (p. 271).</p>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb757-1" data-line-number="1">d &lt;-</a>
<a class="sourceLine" id="cb757-2" data-line-number="2"><span class="st">  </span><span class="kw">crossing</span>(<span class="dt">omega =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length),</a>
<a class="sourceLine" id="cb757-3" data-line-number="3">           <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb757-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior =</span> <span class="kw">ifelse</span>(omega <span class="op">==</span><span class="st"> </span><span class="fl">.25</span>, <span class="kw">dbeta</span>(theta, <span class="fl">3.5</span>, <span class="fl">8.5</span>),</a>
<a class="sourceLine" id="cb757-5" data-line-number="5">                          <span class="kw">ifelse</span>(omega <span class="op">==</span><span class="st"> </span><span class="fl">.75</span>, <span class="kw">dbeta</span>(theta, <span class="fl">8.5</span>, <span class="fl">3.5</span>),</a>
<a class="sourceLine" id="cb757-6" data-line-number="6">                                 <span class="dv">0</span>)))</a>
<a class="sourceLine" id="cb757-7" data-line-number="7">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb757-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> omega, <span class="dt">fill =</span> prior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb757-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_raster</span>(<span class="dt">interpolate =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb757-10" data-line-number="10"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;A&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb757-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb757-12" data-line-number="12">       <span class="dt">y =</span> <span class="kw">expression</span>(omega)) <span class="op">+</span></a>
<a class="sourceLine" id="cb757-13" data-line-number="13"><span class="st">  </span><span class="kw">coord_equal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb757-14" data-line-number="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb757-15" data-line-number="15">        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /></p>
<p>This time we’ll separate <span class="math inline">\(p_{m = 1}(\theta)\)</span> and <span class="math inline">\(p_{m = 2}(\theta)\)</span> into the two short plots on the right of the next row down.</p>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb758-1" data-line-number="1">p1 &lt;-</a>
<a class="sourceLine" id="cb758-2" data-line-number="2"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb758-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(omega <span class="op">==</span><span class="st"> </span><span class="fl">.75</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb758-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb758-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> prior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb758-8" data-line-number="8">       <span class="dt">y =</span> <span class="kw">expression</span>(<span class="kw">p</span>(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>omega<span class="op">==</span>.<span class="dv">75</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-9" data-line-number="9"><span class="st">   </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb758-10" data-line-number="10"></a>
<a class="sourceLine" id="cb758-11" data-line-number="11">p2 &lt;-</a>
<a class="sourceLine" id="cb758-12" data-line-number="12"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb758-13" data-line-number="13"><span class="st">  </span><span class="kw">filter</span>(omega <span class="op">==</span><span class="st"> </span><span class="fl">.25</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb758-14" data-line-number="14"><span class="st">  </span></a>
<a class="sourceLine" id="cb758-15" data-line-number="15"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> prior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-17" data-line-number="17"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb758-18" data-line-number="18">       <span class="dt">y =</span> <span class="kw">expression</span>(<span class="kw">p</span>(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>omega<span class="op">==</span>.<span class="dv">25</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb758-19" data-line-number="19"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb758-20" data-line-number="20"></a>
<a class="sourceLine" id="cb758-21" data-line-number="21"><span class="co"># we&#39;ll put them together with help from patchwork</span></a>
<a class="sourceLine" id="cb758-22" data-line-number="22"><span class="kw">library</span>(patchwork)</a>
<a class="sourceLine" id="cb758-23" data-line-number="23"></a>
<a class="sourceLine" id="cb758-24" data-line-number="24">p1 <span class="op">/</span><span class="st"> </span>p2</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /></p>
<p>We can continue to build on those sensibilities for the middle panel of the same row. Here we’re literally adding <span class="math inline">\(p_{m = 1}(\theta)\)</span> to <span class="math inline">\(p_{m = 2}(\theta)\)</span> and taking their average.</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb759-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb759-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d_75 =</span> <span class="kw">dbeta</span>(<span class="dt">x =</span> theta, <span class="dt">shape1 =</span> <span class="fl">8.5</span>, <span class="dt">shape2 =</span> <span class="fl">3.5</span>),</a>
<a class="sourceLine" id="cb759-3" data-line-number="3">         <span class="dt">d_25 =</span> <span class="kw">dbeta</span>(<span class="dt">x =</span> theta, <span class="dt">shape1 =</span> <span class="fl">3.5</span>, <span class="dt">shape2 =</span> <span class="fl">8.5</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb759-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean_prior =</span> (d_<span class="dv">75</span> <span class="op">+</span><span class="st"> </span>d_<span class="dv">25</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb759-5" data-line-number="5"></a>
<a class="sourceLine" id="cb759-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> mean_prior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb759-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb759-8" data-line-number="8"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb759-9" data-line-number="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb759-10" data-line-number="10">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(theta))) <span class="op">+</span></a>
<a class="sourceLine" id="cb759-11" data-line-number="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /></p>
<p>We need the Bernoulli likelihood function for the next step.</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb760-1" data-line-number="1">bernoulli_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(theta, data) {</a>
<a class="sourceLine" id="cb760-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb760-3" data-line-number="3">  n &lt;-<span class="st"> </span><span class="kw">length</span>(data)</a>
<a class="sourceLine" id="cb760-4" data-line-number="4">  z &lt;-<span class="st"> </span><span class="kw">sum</span>(data)</a>
<a class="sourceLine" id="cb760-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb760-6" data-line-number="6">  <span class="kw">return</span>(theta<span class="op">^</span>z <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span>(n <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(data)))</a>
<a class="sourceLine" id="cb760-7" data-line-number="7">}</a></code></pre></div>
<p>Time to feed our data and the parameter space into <code>bernoulli_likelihood()</code>, which will allow us to make the 2-dimensional density plot at the heart of Figure 10.3.</p>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb761-1" data-line-number="1">n &lt;-<span class="st"> </span><span class="dv">9</span></a>
<a class="sourceLine" id="cb761-2" data-line-number="2">z &lt;-<span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb761-3" data-line-number="3"></a>
<a class="sourceLine" id="cb761-4" data-line-number="4">trial_data &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">times =</span> <span class="kw">c</span>(n <span class="op">-</span><span class="st"> </span>z, z))</a>
<a class="sourceLine" id="cb761-5" data-line-number="5"></a>
<a class="sourceLine" id="cb761-6" data-line-number="6">d &lt;-</a>
<a class="sourceLine" id="cb761-7" data-line-number="7"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb761-8" data-line-number="8"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">likelihood =</span> <span class="kw">bernoulli_likelihood</span>(<span class="dt">theta =</span> theta, </a>
<a class="sourceLine" id="cb761-9" data-line-number="9">                                           <span class="dt">data  =</span> trial_data))</a>
<a class="sourceLine" id="cb761-10" data-line-number="10"></a>
<a class="sourceLine" id="cb761-11" data-line-number="11">d <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb761-12" data-line-number="12"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> omega, <span class="dt">fill =</span> likelihood)) <span class="op">+</span></a>
<a class="sourceLine" id="cb761-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_raster</span>(<span class="dt">interpolate =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb761-14" data-line-number="14"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;A&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb761-15" data-line-number="15"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb761-16" data-line-number="16">       <span class="dt">y =</span> <span class="kw">expression</span>(omega)) <span class="op">+</span></a>
<a class="sourceLine" id="cb761-17" data-line-number="17"><span class="st">  </span><span class="kw">coord_equal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb761-18" data-line-number="18"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb761-19" data-line-number="19">        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /></p>
<p>Now we just need the marginal likelihood, <span class="math inline">\(p(D)\)</span>, to compute the posterior. Our first depiction will be the middle panel of the second row from the bottom–the panel with the uneven dolphin fins.</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb762-1" data-line-number="1">d &lt;-</a>
<a class="sourceLine" id="cb762-2" data-line-number="2"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb762-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">marginal_likelihood =</span> <span class="kw">sum</span>(prior <span class="op">*</span><span class="st"> </span>likelihood)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb762-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">posterior =</span> (prior <span class="op">*</span><span class="st"> </span>likelihood) <span class="op">/</span><span class="st"> </span>marginal_likelihood) </a>
<a class="sourceLine" id="cb762-5" data-line-number="5"></a>
<a class="sourceLine" id="cb762-6" data-line-number="6">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb762-7" data-line-number="7"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> omega, <span class="dt">fill =</span> posterior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb762-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_raster</span>(<span class="dt">interpolate =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb762-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;A&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb762-10" data-line-number="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb762-11" data-line-number="11">       <span class="dt">y =</span> <span class="kw">expression</span>(omega)) <span class="op">+</span></a>
<a class="sourceLine" id="cb762-12" data-line-number="12"><span class="st">  </span><span class="kw">coord_equal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb762-13" data-line-number="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb762-14" data-line-number="14">        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /></p>
<p>Here, then, is a way to get the panel in on the right of the second row from the bottom.</p>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb763-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb763-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">marginal =</span> (posterior <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(posterior)) <span class="op">*</span><span class="st"> </span><span class="dv">25</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb763-3" data-line-number="3"></a>
<a class="sourceLine" id="cb763-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> omega, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> marginal)) <span class="op">+</span></a>
<a class="sourceLine" id="cb763-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb763-6" data-line-number="6"><span class="st">  </span><span class="kw">coord_flip</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb763-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Remember, the scale on the x is arbitrary.&quot;</span>,</a>
<a class="sourceLine" id="cb763-8" data-line-number="8">       <span class="dt">x =</span> <span class="kw">expression</span>(omega),</a>
<a class="sourceLine" id="cb763-9" data-line-number="9">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(omega<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>D))) <span class="op">+</span></a>
<a class="sourceLine" id="cb763-10" data-line-number="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /></p>
<p>To make the middle bottom panel of Figure 10.3, we have to average the posterior values of <span class="math inline">\(\theta\)</span> over the grid of <span class="math inline">\(\omega\)</span> values. That is, we have to marginalize.</p>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb764-1" data-line-number="1"> d <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb764-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(theta) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb764-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">marginal_theta =</span> <span class="kw">mean</span>(posterior)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb764-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb764-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> marginal_theta)) <span class="op">+</span></a>
<a class="sourceLine" id="cb764-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb764-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb764-8" data-line-number="8">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>D))) <span class="op">+</span></a>
<a class="sourceLine" id="cb764-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /></p>
<p>For the lower right panel of Figure 10.3, we’ll <code>filter()</code> to our two focal values of <span class="math inline">\(\omega\)</span> and then facet by them.</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb765-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb765-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(omega <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(.<span class="dv">25</span>, <span class="fl">.75</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb765-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">omega =</span> <span class="kw">str_c</span>(<span class="st">&quot;omega == &quot;</span>, omega)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb765-4" data-line-number="4"></a>
<a class="sourceLine" id="cb765-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> posterior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb765-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb765-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb765-8" data-line-number="8">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>omega))) <span class="op">+</span></a>
<a class="sourceLine" id="cb765-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb765-10" data-line-number="10"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>omega, <span class="dt">ncol =</span> <span class="dv">1</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, <span class="dt">labeller =</span> label_parsed)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /></p>
<p>Do note the different scales on the <span class="math inline">\(y\)</span>. Here’s what they’d look like on the same scale.</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb766-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb766-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(omega <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(.<span class="dv">25</span>, <span class="fl">.75</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb766-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">omega =</span> <span class="kw">str_c</span>(<span class="st">&quot;omega == &quot;</span>, omega)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb766-4" data-line-number="4"></a>
<a class="sourceLine" id="cb766-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> posterior)) <span class="op">+</span></a>
<a class="sourceLine" id="cb766-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb766-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(theta),</a>
<a class="sourceLine" id="cb766-8" data-line-number="8">       <span class="dt">y =</span> <span class="kw">expression</span>(Marginal<span class="op">~</span><span class="kw">p</span>(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span>omega))) <span class="op">+</span></a>
<a class="sourceLine" id="cb766-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb766-10" data-line-number="10"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>omega, <span class="dt">ncol =</span> <span class="dv">1</span>, <span class="dt">labeller =</span> label_parsed)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /></p>
<p>Hopefully that helps build the intuition of what Kruschke meant when he wrote “<em>visual inspection suggests that the ratio of the heights is about 5 to 1, which matches the Bayes factor of 4.68 that we computed exactly in the previous section</em>” (p. 273, <em>emphasis</em> in the original).</p>
<p>Using the grid, you might compute that BF like this.</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb767-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb767-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(omega <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(.<span class="dv">25</span>, <span class="fl">.75</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb767-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(omega) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb767-4" data-line-number="4"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">sum_posterior =</span> <span class="kw">sum</span>(posterior)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb767-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;model_2&quot;</span>, <span class="st">&quot;model_1&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb767-6" data-line-number="6"><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="op">-</span>omega, </a>
<a class="sourceLine" id="cb767-7" data-line-number="7">              <span class="dt">names_from =</span> model,</a>
<a class="sourceLine" id="cb767-8" data-line-number="8">              <span class="dt">values_from =</span> sum_posterior) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-9" data-line-number="9"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">BF =</span> model_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>model_<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##      BF
##   &lt;dbl&gt;
## 1  4.68</code></pre>
</div>
</div>
<div id="solution-by-mcmc" class="section level2">
<h2><span class="header-section-number">10.3</span> Solution by MCMC</h2>
<p>Kruschke started with: “For large, complex models, we cannot derive <span class="math inline">\(p(D | m)\)</span> analytically or with grid approximation, and therefore we will approximate the posterior probabilities using MCMC methods” (p. 274). He’s not kidding. Welcome to modern Bayes.</p>
<div id="nonhierarchical-mcmc-computation-of-each-models-marginal-likelihood." class="section level3">
<h3><span class="header-section-number">10.3.1</span> Nonhierarchical MCMC computation of each model’s marginal likelihood.</h3>
<p>Before you get excited, Kruschke warned: “For complex models, this method might not be tractable. [But] for the simple application here, however, the method works well, as demonstrated in the next section” (p. 277).</p>
<div id="implementation-with-jags-brms." class="section level4">
<h4><span class="header-section-number">10.3.1.1</span> Implementation with <del>JAGS</del> brms.</h4>
<p>Load <strong>brms</strong>.</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb769-1" data-line-number="1"><span class="kw">library</span>(brms)</a></code></pre></div>
<p>Let’s save the <code>trial_data</code> as a tibble.</p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb770-1" data-line-number="1">trial_data &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb770-2" data-line-number="2"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">y =</span> trial_data)</a></code></pre></div>
<p>Time to learn a new <strong>brms</strong> skill. When you want to enter variables into the parameters defining priors in <code>brms::brm()</code>, you need to specify them using the <code>stanvar()</code> function. Since we want to do this for two variables, we’ll use <code>stanvar()</code> twice and save the results as an object, conveniently named <code>stanvars</code>.</p>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb771-1" data-line-number="1">omega &lt;-<span class="st"> </span><span class="fl">.75</span></a>
<a class="sourceLine" id="cb771-2" data-line-number="2">kappa &lt;-<span class="st"> </span><span class="dv">12</span></a>
<a class="sourceLine" id="cb771-3" data-line-number="3"></a>
<a class="sourceLine" id="cb771-4" data-line-number="4">stanvars &lt;-</a>
<a class="sourceLine" id="cb771-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(     omega  <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">name =</span> <span class="st">&quot;my_alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb771-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">name =</span> <span class="st">&quot;my_beta&quot;</span>)</a></code></pre></div>
<p>Now we have our <code>stanvars</code> object, we are ready to fit the first model (i.e., the model for which <span class="math inline">\(\omega = .75\)</span>).</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb772-1" data-line-number="1">fit10<span class="fl">.1</span> &lt;-</a>
<a class="sourceLine" id="cb772-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> trial_data, </a>
<a class="sourceLine" id="cb772-3" data-line-number="3">      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> identity),</a>
<a class="sourceLine" id="cb772-4" data-line-number="4">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb772-5" data-line-number="5">      <span class="kw">prior</span>(<span class="kw">beta</span>(my_alpha, my_beta), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb772-6" data-line-number="6">      <span class="dt">iter =</span> <span class="dv">11000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb772-7" data-line-number="7">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb772-8" data-line-number="8">      <span class="dt">stanvars =</span> stanvars,</a>
<a class="sourceLine" id="cb772-9" data-line-number="9">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.999</span>),</a>
<a class="sourceLine" id="cb772-10" data-line-number="10">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.01&quot;</span>)</a></code></pre></div>
<p>Note how we fed our <code>stanvars</code> object into the <code>stanvars</code> function.</p>
<p>Anyway, let’s inspect the chains.</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb773-1" data-line-number="1"><span class="kw">plot</span>(fit10<span class="fl">.1</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-28-1.png" style="display: block; margin: auto;" /></p>
<p>They look great. Now we glance at the model summary.</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb774-1" data-line-number="1"><span class="kw">print</span>(fit10<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##  Family: bernoulli 
##   Links: mu = identity 
## Formula: y ~ 1 
##    Data: trial_data (Number of observations: 9) 
## Samples: 4 chains, each with iter = 11000; warmup = 1000; thin = 1;
##          total post-warmup samples = 40000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.69      0.10     0.48     0.86 1.00     8007     9306
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Next we’ll follow Kruschke and extract the posterior samples, saving them as <code>theta</code>.</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb776-1" data-line-number="1">theta &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit10<span class="fl">.1</span>)</a>
<a class="sourceLine" id="cb776-2" data-line-number="2"></a>
<a class="sourceLine" id="cb776-3" data-line-number="3"><span class="kw">head</span>(theta)</a></code></pre></div>
<pre><code>##   b_Intercept      lp__
## 1   0.7263424 -4.691665
## 2   0.7626307 -4.815941
## 3   0.7222605 -4.686314
## 4   0.8012281 -5.125448
## 5   0.7373272 -4.714354
## 6   0.6857306 -4.707360</code></pre>
<p>The <code>fixef()</code> function will return the posterior summaries for the model intercept (i.e., <span class="math inline">\(\theta\)</span>). We can then index and save the desired summaries.</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb778-1" data-line-number="1"><span class="kw">fixef</span>(fit10<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##           Estimate Est.Error      Q2.5    Q97.5
## Intercept 0.691113  0.098457 0.4820692 0.863507</code></pre>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb780-1" data-line-number="1">(mean_theta &lt;-<span class="st"> </span><span class="kw">fixef</span>(fit10<span class="fl">.1</span>)[<span class="dv">1</span>])</a></code></pre></div>
<pre><code>## [1] 0.691113</code></pre>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb782-1" data-line-number="1">(sd_theta &lt;-<span class="st"> </span><span class="kw">fixef</span>(fit10<span class="fl">.1</span>)[<span class="dv">2</span>])</a></code></pre></div>
<pre><code>## [1] 0.098457</code></pre>
<p>Now we’ll convert them to the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters, <code>a_post</code> and <code>b_post</code>, respectively.</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb784-1" data-line-number="1">a_post &lt;-<span class="st">      </span>mean_theta  <span class="op">*</span><span class="st"> </span>( mean_theta <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">/</span><span class="st"> </span>sd_theta<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb784-2" data-line-number="2">b_post &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">*</span><span class="st"> </span>( mean_theta <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">/</span><span class="st"> </span>sd_theta<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a></code></pre></div>
<p>Recall we’ve already defined several values.</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb785-1" data-line-number="1">n     &lt;-<span class="st"> </span><span class="dv">9</span></a>
<a class="sourceLine" id="cb785-2" data-line-number="2">z     &lt;-<span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb785-3" data-line-number="3">omega &lt;-<span class="st"> </span><span class="fl">.75</span></a>
<a class="sourceLine" id="cb785-4" data-line-number="4">kappa &lt;-<span class="st"> </span><span class="dv">12</span></a></code></pre></div>
<p>The reason we’re saving all these values is we’re aiming to compute <span class="math inline">\(p(D)\)</span>, the probability of the data (i.e., the marginal likelihood), given the model. But our intermediary step will be computing its reciprocal, <span class="math inline">\(\frac{1}{p(D)}\)</span>. Here we’ll express Kruschke’s <code>oneOverPD</code> as a function, <code>one_over_pd()</code>.</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb786-1" data-line-number="1">one_over_pd &lt;-<span class="st"> </span><span class="cf">function</span>(theta) {</a>
<a class="sourceLine" id="cb786-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb786-3" data-line-number="3">  <span class="kw">mean</span>(<span class="kw">dbeta</span>(theta, a_post, b_post ) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb786-4" data-line-number="4"><span class="st">         </span>(theta<span class="op">^</span>z <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span>(n <span class="op">-</span><span class="st"> </span>z) <span class="op">*</span><span class="st"> </span></a>
<a class="sourceLine" id="cb786-5" data-line-number="5"><span class="st">            </span><span class="kw">dbeta</span>(theta, omega <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span> )))</a>
<a class="sourceLine" id="cb786-6" data-line-number="6">  </a>
<a class="sourceLine" id="cb786-7" data-line-number="7">}</a></code></pre></div>
<p>We’re ready to use <code>one_over_pd()</code> to help compute <span class="math inline">\(p(D)\)</span>.</p>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb787-1" data-line-number="1">theta <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb787-2" data-line-number="2"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">pd =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">one_over_pd</span>(<span class="dt">theta =</span> b_Intercept))</a></code></pre></div>
<pre><code>##            pd
## 1 0.002338466</code></pre>
<p>That matches up nicely with Kruschke’s value! Let’s rinse, wash, and repeat for <span class="math inline">\(\omega = .25\)</span>. First, we’ll need to redefine <code>omega</code> and our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb789-1" data-line-number="1">omega &lt;-<span class="st"> </span><span class="fl">.25</span></a>
<a class="sourceLine" id="cb789-2" data-line-number="2"></a>
<a class="sourceLine" id="cb789-3" data-line-number="3">stanvars &lt;-</a>
<a class="sourceLine" id="cb789-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(     omega  <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">name =</span> <span class="st">&quot;my_alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb789-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">name =</span> <span class="st">&quot;my_beta&quot;</span>)</a></code></pre></div>
<p>Fit the model.</p>
<div class="sourceCode" id="cb790"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb790-1" data-line-number="1">fit10<span class="fl">.2</span> &lt;-</a>
<a class="sourceLine" id="cb790-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> trial_data, </a>
<a class="sourceLine" id="cb790-3" data-line-number="3">      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> identity),</a>
<a class="sourceLine" id="cb790-4" data-line-number="4">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb790-5" data-line-number="5">      <span class="kw">prior</span>(<span class="kw">beta</span>(my_alpha, my_beta), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb790-6" data-line-number="6">      <span class="dt">iter =</span> <span class="dv">11000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb790-7" data-line-number="7">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb790-8" data-line-number="8">      <span class="dt">stanvars =</span> stanvars,</a>
<a class="sourceLine" id="cb790-9" data-line-number="9">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.999</span>),</a>
<a class="sourceLine" id="cb790-10" data-line-number="10">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.02&quot;</span>)</a></code></pre></div>
<p>We’ll do the rest in bulk.</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb791-1" data-line-number="1">theta &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit10<span class="fl">.2</span>)</a>
<a class="sourceLine" id="cb791-2" data-line-number="2"></a>
<a class="sourceLine" id="cb791-3" data-line-number="3">mean_theta &lt;-<span class="st"> </span><span class="kw">fixef</span>(fit10<span class="fl">.2</span>)[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb791-4" data-line-number="4">sd_theta   &lt;-<span class="st"> </span><span class="kw">fixef</span>(fit10<span class="fl">.2</span>)[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb791-5" data-line-number="5"></a>
<a class="sourceLine" id="cb791-6" data-line-number="6">a_post &lt;-<span class="st">      </span>mean_theta  <span class="op">*</span><span class="st"> </span>( mean_theta <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">/</span><span class="st"> </span>sd_theta<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb791-7" data-line-number="7">b_post &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">*</span><span class="st"> </span>( mean_theta <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_theta) <span class="op">/</span><span class="st"> </span>sd_theta<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb791-8" data-line-number="8"></a>
<a class="sourceLine" id="cb791-9" data-line-number="9">theta <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb791-10" data-line-number="10"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">pd =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">one_over_pd</span>(<span class="dt">theta =</span> b_Intercept))</a></code></pre></div>
<pre><code>##             pd
## 1 0.0004992476</code></pre>
<p>Boom!</p>
</div>
</div>
<div id="hierarchical-mcmc-computation-of-relative-model-probability-is-not-available-in-brms-well-cover-information-criteria-instead." class="section level3">
<h3><span class="header-section-number">10.3.2</span> Hierarchical MCMC computation <del>of relative model probability</del> is not available in brms: We’ll cover information criteria instead.</h3>
<p>I’m not aware of a way to specify a model “in which the top-level parameter is the index across models” in <strong>brms</strong> (p. 278). If you know of a way, <a href="https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse/issues">share your code</a>.</p>
<p>However, we do have options. We can compare and weight models using information criteria, about which you can learn more <a href="https://youtu.be/t0pRuy1_190?t=978">here</a>. In <strong>brms</strong>, the LOO and WAIC are two primary information criteria available. You can compute them for a given model with the <code>loo()</code> and <code>waic()</code> functions, respectively. Here’s a quick example of how to use the <code>waic()</code> function.</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb793-1" data-line-number="1"><span class="kw">waic</span>(fit10<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## Computed from 40000 by 9 log-likelihood matrix
## 
##           Estimate  SE
## elpd_waic     -6.2 1.3
## p_waic         0.5 0.1
## waic          12.5 2.7</code></pre>
<p>We’ll explain that output in a bit. Before we do, you should know the current recommended workflow for information criteria with <strong>brms</strong> models is to use the <code>add_criterion()</code> function, which will allow us to compute information-criterion-related output and save it to our <strong>brms</strong> fit objects. Here’s how to do that with both our fits.</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb795-1" data-line-number="1">fit10<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.1</span>, <span class="dt">criterion =</span> <span class="kw">c</span>(<span class="st">&quot;loo&quot;</span>, <span class="st">&quot;waic&quot;</span>))</a>
<a class="sourceLine" id="cb795-2" data-line-number="2">fit10<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.2</span>, <span class="dt">criterion =</span> <span class="kw">c</span>(<span class="st">&quot;loo&quot;</span>, <span class="st">&quot;waic&quot;</span>))</a></code></pre></div>
<p>You can extract the same WAIC output for <code>fit10.1</code> we saw above by executing <code>fit10.1$criteria$waic</code>. Here we look at the LOO summary for <code>fit10.2</code>, instead.</p>
<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb796-1" data-line-number="1">fit10<span class="fl">.2</span><span class="op">$</span>criteria<span class="op">$</span>loo</a></code></pre></div>
<pre><code>## 
## Computed from 40000 by 9 log-likelihood matrix
## 
##          Estimate  SE
## elpd_loo     -7.1 0.3
## p_loo         0.5 0.0
## looic        14.1 0.6
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>You get a wealth of output, more of which can be seen by executing <code>str(fit10.1$criteria$loo)</code>. First, notice the message “All Pareto k estimates are good (k &lt; 0.5).” Pareto <span class="math inline">\(k\)</span> values can be <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html#plotting-pareto-k-diagnostics">used for diagnostics</a>. Each case in the data gets its own <span class="math inline">\(k\)</span> value and we like it when those <span class="math inline">\(k\)</span>s are low. The makers of the <a href="https://github.com/stan-dev/loo"><strong>loo</strong> package</a> get worried when <span class="math inline">\(k\)</span> values exceed 0.7 and, as a result, we will get warning messages when they do. Happily, we have no such warning messages in this example.</p>
<p>In the main section, we get estimates for the expected log predictive density (<code>elpd_loo</code>), the estimated effective number of parameters (<code>p_loo</code>), and the Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO; <code>looic</code>). Each estimate comes with a standard error (i.e., <code>SE</code>). Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the estimate of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower information criteria. With the <code>loo_compare()</code> function, we can compute a formal difference score between two models.</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb798-1" data-line-number="1"><span class="kw">loo_compare</span>(fit10<span class="fl">.1</span>, fit10<span class="fl">.2</span>, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a></code></pre></div>
<pre><code>##         elpd_diff se_diff
## fit10.1  0.0       0.0   
## fit10.2 -0.8       1.7</code></pre>
<p>The <code>loo_compare()</code> output rank orders the models such that the best fitting model appears on top. All models receive a difference score relative to the best model. Here the best fitting model is <code>fit10.1</code> and since the LOO for <code>fit10.1</code> minus itself is zero, the values in the top row are all zero.</p>
<p>Each difference score also comes with a standard error. In this case, even though <code>fit10.1</code> has the lower estimates, the standard error is twice the magnitude of the difference score. So the LOO difference score puts the two models on similar footing. You can do a similar analysis with the WAIC estimates.</p>
<p>In addition to difference-score comparisons, you can also use the LOO or WAIC for AIC-type model weighting. In <strong>brms</strong>, you do this with the <code>model_weights()</code> function.</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb800-1" data-line-number="1">(mw &lt;-<span class="st"> </span><span class="kw">model_weights</span>(fit10<span class="fl">.1</span>, fit10<span class="fl">.2</span>))</a></code></pre></div>
<pre><code>##  fit10.1  fit10.2 
## 0.830191 0.169809</code></pre>
<p>I don’t know that I’d call these weights probabilities, but they do sum to one. In this case, the analysis suggests we put about five times more weight to <code>fit10.1</code> relative to <code>fit10.2</code>.</p>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb802-1" data-line-number="1">mw[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>mw[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>##  fit10.1 
## 4.888969</code></pre>
<p>With <code>brms::model_weights()</code>, we have a variety of weighting schemes avaliable to us. Since we didn’t specify any in the <code>weights</code> argument, we used the default <code>&quot;stacking&quot;</code>, which is–perhaps confusingly given the name–the stacking method according to the <a href="https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227">paper by Yao, Vehtari, Simpson, and Gelman</a>. Vehtari has <a href="https://statmodeling.stat.columbia.edu/2017/04/11/stacking-pseudo-bma-and-aic-weights/">written about the paper</a> on Gelman’s blog, too. But anyway, the point is that different weighting schemes might not produce the same results. For example, here’s the result from weighting using the WAIC.</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb804-1" data-line-number="1"><span class="kw">model_weights</span>(fit10<span class="fl">.1</span>, fit10<span class="fl">.2</span>, <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>)</a></code></pre></div>
<pre><code>##   fit10.1   fit10.2 
## 0.6967995 0.3032005</code></pre>
<p>The results are similar, for sure. But they’re not the same. The stacking method via the <strong>brms</strong> default <code>weights = &quot;stacking&quot;</code> is the current preferred method by the folks on the Stan team (e.g., the authors of the above linked paper).</p>
<p>For more on stacking and other weighting schemes, see Vehtari and Gabry’s vignette <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-weights.html"><em>Bayesian Stacking and Pseudo-BMA weights using the loo package</em></a> or Vehtari’s <a href="https://github.com/avehtari/modelselection_tutorial">modelselection_tutorial GitHub repository</a>. But don’t worry. We will have more opportunities to practice with information criteria, model weights, and such later in this project.</p>
<div id="using-no-need-to-use-pseudo-priors-to-reduce-autocorrelation." class="section level4">
<h4><span class="header-section-number">10.3.2.1</span> <del>Using</del> [No need to use] pseudo-priors to reduce autocorrelation.</h4>
<p>Since we didn’t use Kruschke’s method from the last subsection, we don’t have the same worry about autocorrelation. For example, here are the autocorrelation plots for <code>fit10.1</code>.</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb806-1" data-line-number="1"><span class="kw">library</span>(bayesplot)</a>
<a class="sourceLine" id="cb806-2" data-line-number="2"></a>
<a class="sourceLine" id="cb806-3" data-line-number="3"><span class="kw">mcmc_acf</span>(<span class="kw">posterior_samples</span>(fit10<span class="fl">.1</span>, <span class="dt">add_chain =</span> T), </a>
<a class="sourceLine" id="cb806-4" data-line-number="4">         <span class="dt">pars =</span> <span class="st">&quot;b_Intercept&quot;</span>,</a>
<a class="sourceLine" id="cb806-5" data-line-number="5">         <span class="dt">lags =</span> <span class="dv">35</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-43-1.png" style="display: block; margin: auto;" /></p>
<p>Our autocorrelations were a little high for HMC, but nowhere near pathological. The results for <code>fit10.2</code> were similar. As you might imagine from the moderate autocorrelations, the <span class="math inline">\(N_{eff}/N\)</span> ratio for <code>b_Intercept</code> wasn’t great.</p>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb807-1" data-line-number="1"><span class="kw">neff_ratio</span>(fit10<span class="fl">.1</span>)[<span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb807-2" data-line-number="2"><span class="st">  </span><span class="kw">mcmc_neff</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb807-3" data-line-number="3"><span class="st">  </span><span class="kw">yaxis_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-44-1.png" style="display: block; margin: auto;" /></p>
<p>But we specified a lot of post-warmup iterations, so we’re still in good shape. Plus, the <span class="math inline">\(\hat R\)</span> was fine.</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb808-1" data-line-number="1"><span class="kw">rhat</span>(fit10<span class="fl">.1</span>)[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## b_Intercept 
##    1.000613</code></pre>
</div>
</div>
<div id="models-with-different-noise-distributions-in-jags-brms." class="section level3">
<h3><span class="header-section-number">10.3.3</span> Models with different “noise” distributions in <del>JAGS</del> brms.</h3>
<blockquote>
<p>Probability distribution[s are] sometimes [called “noise”] distribution[s] because [they describe] the random variability of the data values around the underlying trend. In more general applications, different models can have different noise distributions. For example, one model might describe the data as log-normal distributed, while another model might describe the data as gamma distributed. (p. 288)</p>
</blockquote>
<p>If there are more than one plausible noise distributions for our data, we might want to compare the models. Kruschke then gave us a general trick in the form of this JAGS code:</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb810-1" data-line-number="1">data {</a>
<a class="sourceLine" id="cb810-2" data-line-number="2">  C &lt;-<span class="st"> </span><span class="dv">10000</span> <span class="co"># JAGS does not warn if too small!</span></a>
<a class="sourceLine" id="cb810-3" data-line-number="3">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb810-4" data-line-number="4">    ones[i] &lt;-<span class="st"> </span><span class="dv">1</span> }</a>
<a class="sourceLine" id="cb810-5" data-line-number="5">} model {</a>
<a class="sourceLine" id="cb810-6" data-line-number="6">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {</a>
<a class="sourceLine" id="cb810-7" data-line-number="7">    spy1[i] &lt;-<span class="st"> </span><span class="kw">pdf1</span>(y[i], parameters1) <span class="op">/</span><span class="st"> </span>C <span class="co"># where pdf1 is a formula</span></a>
<a class="sourceLine" id="cb810-8" data-line-number="8">    spy2[i] &lt;-<span class="st"> </span><span class="kw">pdf2</span>(y[i], parameters2) <span class="op">/</span><span class="st"> </span>C <span class="co"># where pdf2 is a formula</span></a>
<a class="sourceLine" id="cb810-9" data-line-number="9">    spy[i]  &lt;-<span class="st"> </span><span class="kw">equals</span>(m,<span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>spy1[i] <span class="op">+</span><span class="st"> </span><span class="kw">equals</span>(m, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>spy2[i]</a>
<a class="sourceLine" id="cb810-10" data-line-number="10">    ones[i] <span class="op">~</span><span class="st"> </span><span class="kw">dbern</span>(spy[i])</a>
<a class="sourceLine" id="cb810-11" data-line-number="11">  }</a>
<a class="sourceLine" id="cb810-12" data-line-number="12">  parameters1 <span class="op">~</span><span class="st"> </span>dprior1...</a>
<a class="sourceLine" id="cb810-13" data-line-number="13">  parameters2 <span class="op">~</span><span class="st"> </span>dprior2...</a>
<a class="sourceLine" id="cb810-14" data-line-number="14">  m <span class="op">~</span><span class="st"> </span><span class="kw">dcat</span>(mPriorProb[])</a>
<a class="sourceLine" id="cb810-15" data-line-number="15">  mPriorProb[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">.5</span></a>
<a class="sourceLine" id="cb810-16" data-line-number="16">  mPriorProb[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="fl">.5</span></a>
<a class="sourceLine" id="cb810-17" data-line-number="17">}</a></code></pre></div>
<p>I’m not aware that we can do this within the Stan/<strong>brms</strong> framework. If I’m in error and you know how, <a href="https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse/issues">please share your code</a>. However, we do have options. In anticipation of Chapter 16, let’s consider Gaussian-like data with thick tails. We might generate some like this:</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb811-1" data-line-number="1"><span class="co"># how many draws would you like?</span></a>
<a class="sourceLine" id="cb811-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="fl">1e3</span></a>
<a class="sourceLine" id="cb811-3" data-line-number="3"></a>
<a class="sourceLine" id="cb811-4" data-line-number="4"><span class="kw">set.seed</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb811-5" data-line-number="5">(d &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y =</span> <span class="kw">rt</span>(n, <span class="dt">df =</span> <span class="dv">7</span>)))</a></code></pre></div>
<pre><code>## # A tibble: 1,000 x 1
##          y
##      &lt;dbl&gt;
##  1  0.0214
##  2 -0.987 
##  3  0.646 
##  4 -0.237 
##  5  0.977 
##  6 -0.200 
##  7  0.781 
##  8 -1.09  
##  9  1.83  
## 10 -0.682 
## # … with 990 more rows</code></pre>
<p>The resulting data look like this.</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb813-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb813-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb813-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb813-4" data-line-number="4">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">30</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb813-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb813-6" data-line-number="6"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-48-1.png" style="display: block; margin: auto;" /></p>
<p>As you’d expect with a small-<span class="math inline">\(\nu\)</span> Student’s <span class="math inline">\(t\)</span>, some of our values are far from the central clump. If you don’t recall, Student’s <span class="math inline">\(t\)</span>-distribution has three parameters: <span class="math inline">\(\nu\)</span>, <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\sigma\)</span>. The Gaussian is a special case of Student’s <span class="math inline">\(t\)</span> for which <span class="math inline">\(\nu = \infty\)</span>. As <span class="math inline">\(\nu\)</span> gets small, the distribution allocates more mass in the tails. From a Gaussian perspective, the small-<span class="math inline">\(\nu\)</span> Student’s <span class="math inline">\(t\)</span> expects more outliers–though it’s a little odd calling them outliers from a small-<span class="math inline">\(\nu\)</span> Student’s <span class="math inline">\(t\)</span> perspective.</p>
<p>Let’s see how well the Gaussian versus the Student’s <span class="math inline">\(t\)</span> likelihoods handle the data. Here we’ll use fairly liberal priors.</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb814-1" data-line-number="1">fit10<span class="fl">.3</span> &lt;-</a>
<a class="sourceLine" id="cb814-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</a>
<a class="sourceLine" id="cb814-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb814-4" data-line-number="4">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb814-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb814-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> sigma)),  <span class="co"># by default, this has a lower bound of 0</span></a>
<a class="sourceLine" id="cb814-7" data-line-number="7">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb814-8" data-line-number="8">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb814-9" data-line-number="9">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.03&quot;</span>)</a>
<a class="sourceLine" id="cb814-10" data-line-number="10"></a>
<a class="sourceLine" id="cb814-11" data-line-number="11">fit10<span class="fl">.4</span> &lt;-</a>
<a class="sourceLine" id="cb814-12" data-line-number="12"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</a>
<a class="sourceLine" id="cb814-13" data-line-number="13">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb814-14" data-line-number="14">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb814-15" data-line-number="15">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb814-16" data-line-number="16">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb814-17" data-line-number="17">                <span class="kw">prior</span>(<span class="kw">gamma</span>(<span class="dv">2</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> nu)),  <span class="co"># this is the brms default prior for nu</span></a>
<a class="sourceLine" id="cb814-18" data-line-number="18">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb814-19" data-line-number="19">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb814-20" data-line-number="20">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.04&quot;</span>)</a></code></pre></div>
<p>In case you were curious, here’s what that default <code>gamma(2, 0.1)</code> prior on <code>nu</code> looks like.</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb815-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">110</span>, <span class="dt">by =</span> <span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb815-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb815-3" data-line-number="3">             <span class="dt">ymax =</span> <span class="kw">dgamma</span>(x, <span class="dv">2</span>, <span class="fl">0.1</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb815-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb815-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb815-6" data-line-number="6"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(p)(nu))) <span class="op">+</span></a>
<a class="sourceLine" id="cb815-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">100</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb815-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-49-1.png" style="display: block; margin: auto;" /></p>
<p>That prior puts most of the probability mass below 50, but the right tail gently fades off into the triple digits, allowing for the possibility of larger estimates.</p>
<p>We can use the <code>posterior_summary()</code> function to get a compact look at the model summaries.</p>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb816-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit10<span class="fl">.3</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##             Estimate Est.Error     Q2.5    Q97.5
## b_Intercept    -0.03      0.04    -0.11     0.05
## sigma           1.25      0.03     1.20     1.31
## lp__        -1646.97      0.98 -1649.49 -1646.02</code></pre>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb818-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit10<span class="fl">.4</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##             Estimate Est.Error     Q2.5    Q97.5
## b_Intercept    -0.01      0.04    -0.08     0.06
## sigma           0.98      0.04     0.90     1.05
## nu              5.76      1.02     4.12     8.06
## lp__        -1590.50      1.26 -1593.76 -1589.07</code></pre>
<p>Now we can compare the two approaches using information criteria. For kicks, we’ll use the WAIC.</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb820-1" data-line-number="1">fit10<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.3</span>, <span class="dt">criterion =</span> <span class="kw">c</span>(<span class="st">&quot;loo&quot;</span>, <span class="st">&quot;waic&quot;</span>))</a>
<a class="sourceLine" id="cb820-2" data-line-number="2">fit10<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.4</span>, <span class="dt">criterion =</span> <span class="kw">c</span>(<span class="st">&quot;loo&quot;</span>, <span class="st">&quot;waic&quot;</span>))</a>
<a class="sourceLine" id="cb820-3" data-line-number="3"></a>
<a class="sourceLine" id="cb820-4" data-line-number="4"><span class="kw">loo_compare</span>(fit10<span class="fl">.3</span>, fit10<span class="fl">.4</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)</a></code></pre></div>
<pre><code>##         elpd_diff se_diff
## fit10.4   0.0       0.0  
## fit10.3 -60.3      40.1</code></pre>
<p>Based on the WAIC difference, we have some support for preferring the Student’s <span class="math inline">\(t\)</span>, but do notice how wide that <code>SE</code> was. We can also compare the models using model weights. Here we’ll use the default weighting scheme.</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb822-1" data-line-number="1"><span class="kw">model_weights</span>(fit10<span class="fl">.3</span>, fit10<span class="fl">.4</span>)</a></code></pre></div>
<pre><code>##    fit10.3    fit10.4 
## 0.03221231 0.96778769</code></pre>
<p>Virtually all of the stacking weight was placed on the Student’s-<span class="math inline">\(t\)</span> model, <code>fit10.4</code>.</p>
<p>Remember what that <span class="math inline">\(p(\nu)\)</span> looked like? Here’s our posterior distribution for <span class="math inline">\(\nu\)</span>.</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb824-1" data-line-number="1"><span class="kw">posterior_samples</span>(fit10<span class="fl">.4</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb824-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> nu)) <span class="op">+</span></a>
<a class="sourceLine" id="cb824-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb824-4" data-line-number="4">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">30</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb824-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb824-6" data-line-number="6"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb824-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;Recall that for the Gaussian, &quot;</span><span class="op">*</span>nu<span class="op">==</span>infinity.),</a>
<a class="sourceLine" id="cb824-8" data-line-number="8">       <span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p)(nu<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span><span class="kw">italic</span>(D)))) <span class="op">+</span></a>
<a class="sourceLine" id="cb824-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-52-1.png" style="display: block; margin: auto;" /></p>
<p>Even though our prior for <span class="math inline">\(\nu\)</span> was relatively weak, the posterior ended up concentrated on values in the middle-single-digit range. Recall the data-generating value was 7.</p>
<p>We can also compare the models using posterior-predictive checks. There are a variety of ways we might do this, but the most convenient way is with <code>brms::pp_check()</code>, which is itself a wrapper for the family of <code>ppc</code> functions from the <strong>bayesplot</strong> package.</p>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb825-1" data-line-number="1"><span class="kw">pp_check</span>(fit10<span class="fl">.3</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-53-1.png" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb826-1" data-line-number="1"><span class="kw">pp_check</span>(fit10<span class="fl">.4</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-53-2.png" style="display: block; margin: auto;" /></p>
<p>The default <code>pp_check()</code> setting allows us to compare the density of the data <span class="math inline">\(y\)</span> (i.e., the dark blue) with 10 density’s simulated from the posterior <span class="math inline">\(y_\text{rep}\)</span> (i.e., the light blue). We prefer models that produce <span class="math inline">\(y_\text{rep}\)</span> distributions resembling <span class="math inline">\(y\)</span>. Though the results from both models were similar, the simulated distributions from <code>fit10.4</code> mimicked the original data a little more convincingly. To learn more about this approach to posterior predictive checks, check out Gabry’s vignette <a href="https://cran.r-project.org/web/packages/bayesplot/vignettes/graphical-ppcs.html"><em>Graphical posterior predictive checks using the bayesplot package</em></a>.</p>
</div>
</div>
<div id="prediction-model-averaging" class="section level2">
<h2><span class="header-section-number">10.4</span> Prediction: Model averaging</h2>
<blockquote>
<p>In many applications of model comparison, the analyst wants to identify the best model and then base predictions of future data on that single best model, denoted with index <span class="math inline">\(b\)</span>. In this case, predictions of future <span class="math inline">\(\hat{y}\)</span> are based exclusively on the likelihood function <span class="math inline">\(p_b(\hat{y} | \theta_b, m = b)\)</span> and the posterior distribution <span class="math inline">\(p_b(\theta_b | D, m = b)\)</span> of the winning model:</p>
<p><span class="math display">\[p_b(\hat y | D, m = b) = \int \text d \theta_b p_b (\hat{y} | \theta_b, m = b) p_b(\theta_b | D, m = b)\]</span></p>
<p>But the full model of the data is actually the complete hierarchical structure that spans all the models being compared, as indicated in Figure 10.1 (p. 267). Therefore, if the hierarchical structure really expresses our prior beliefs, then the most complete prediction of future data takes into account all the models, weighted by their posterior credibilities. In other words, we take a weighted average across the models, with the weights being the posterior probabilities of the models. Instead of conditionalizing on the winning model, we have</p>
<p><span class="math display">\[\begin{align*}
p (\hat y | D) &amp; = \sum_m p (\hat y | D, m) p (m | D) \\
&amp; = \sum_m \int \text d \theta_m p_m (\hat{y} | \theta_m, m) p_m(\theta_m | D, m) p (m | D)
\end{align*}\]</span></p>
<p>This is called model averaging. (p. 289)</p>
</blockquote>
<p>Okay, while the concept of model averaging is of great interest, we aren’t going to be able to follow this approach to it within the Stan/<strong>brms</strong> paradigm. This, recall, is because our paradigm doesn’t allow for a hierarchical organization of models in the same way JAGS does. However, we can still play the model averaging game with extensions of our model weighting paradigm, above. Before we get into the details,</p>
<blockquote>
<p>recall that there were two models of mints that created the coin, with one mint being tail-biased with mode <span class="math inline">\(\omega = 0.25\)</span> and one mint being head-biased with mode <span class="math inline">\(\omega = 0.75\)</span> The two subpanels in the lower-right [of Figure 10.3] illustrate the posterior distributions on <span class="math inline">\(\omega\)</span> within each model, <span class="math inline">\(p(\theta | D, \omega = 0.25)\)</span> and <span class="math inline">\(p(\theta | D, \omega = 0.75)\)</span> The winning model was <span class="math inline">\(\omega = 0.75\)</span>, and therefore the predicted value of future data, based on the winning model alone, would use <span class="math inline">\(p(\theta | D, \omega = 0.75)\)</span>. (p. 289)</p>
</blockquote>
<p>Here’s the histogram for <span class="math inline">\(p(\theta | D, \omega = 0.75)\)</span>, which we generate from our <code>fit10.1</code>.</p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb827-1" data-line-number="1"><span class="kw">library</span>(tidybayes)</a>
<a class="sourceLine" id="cb827-2" data-line-number="2"></a>
<a class="sourceLine" id="cb827-3" data-line-number="3"><span class="kw">posterior_samples</span>(fit10<span class="fl">.1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb827-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_Intercept, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb827-5" data-line-number="5"><span class="st">  </span><span class="kw">stat_histintervalh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>),</a>
<a class="sourceLine" id="cb827-6" data-line-number="6">                     <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">slab_color =</span> <span class="st">&quot;grey92&quot;</span>,</a>
<a class="sourceLine" id="cb827-7" data-line-number="7">                     <span class="dt">breaks =</span> <span class="dv">40</span>, <span class="dt">slab_size =</span> <span class="fl">.25</span>, <span class="dt">outline_bars =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb827-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb827-9" data-line-number="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;The posterior for the probability, given fit10.1&quot;</span>,</a>
<a class="sourceLine" id="cb827-10" data-line-number="10">       <span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p)(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span><span class="kw">italic</span>(D)<span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span>omega<span class="op">==</span>.<span class="dv">75</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb827-11" data-line-number="11"><span class="st">  </span><span class="kw">xlim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb827-12" data-line-number="12"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-54-1.png" style="display: block; margin: auto;" /></p>
<blockquote>
<p>But the overall model included <span class="math inline">\(\omega = 0.75\)</span>, and if we use the overall model, then the predicted value of future data should be based on the complete posterior summed across values of <span class="math inline">\(\omega\)</span>. The complete posterior distribution [is] <span class="math inline">\(p(\theta | D)\)</span> (p. 289).</p>
</blockquote>
<p>The cool thing about the model weighting stuff we learned about earlier is that you can use those model weights to average across models. Again, we’re not weighting the models by posterior probabilities the way Kruschke discussed in text. However, the spirit is similar. We can use the <code>brms::pp_average()</code> function to make posterior predictive prediction with mixtures of the models, weighted by our chosen weighting scheme. Here, we’ll go with the default stacking weights.</p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb828-1" data-line-number="1">nd &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb828-2" data-line-number="2"></a>
<a class="sourceLine" id="cb828-3" data-line-number="3">pp_a &lt;-</a>
<a class="sourceLine" id="cb828-4" data-line-number="4"><span class="st">  </span><span class="kw">pp_average</span>(fit10<span class="fl">.1</span>, fit10<span class="fl">.2</span>, </a>
<a class="sourceLine" id="cb828-5" data-line-number="5">             <span class="dt">newdata =</span> nd,</a>
<a class="sourceLine" id="cb828-6" data-line-number="6">             <span class="co"># this line is not necessary, but you should see how to choose weighing methods</span></a>
<a class="sourceLine" id="cb828-7" data-line-number="7">             <span class="dt">weights =</span> <span class="st">&quot;stacking&quot;</span>,</a>
<a class="sourceLine" id="cb828-8" data-line-number="8">             <span class="dt">method =</span> <span class="st">&quot;fitted&quot;</span>,</a>
<a class="sourceLine" id="cb828-9" data-line-number="9">             <span class="dt">summary =</span> F) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb828-10" data-line-number="10"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb828-11" data-line-number="11"><span class="st">  </span><span class="kw">set_names</span>(<span class="st">&quot;theta&quot;</span>)</a>
<a class="sourceLine" id="cb828-12" data-line-number="12"></a>
<a class="sourceLine" id="cb828-13" data-line-number="13"><span class="co"># what does this produce?</span></a>
<a class="sourceLine" id="cb828-14" data-line-number="14"><span class="kw">head</span>(pp_a) </a></code></pre></div>
<pre><code>## # A tibble: 6 x 1
##   theta
##   &lt;dbl&gt;
## 1 0.730
## 2 0.594
## 3 0.736
## 4 0.853
## 5 0.839
## 6 0.744</code></pre>
<p>We can plot our model-averaged <span class="math inline">\(\theta\)</span> with a little help from good old <code>tidybayes::stat_histintervalh()</code>.</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb830-1" data-line-number="1">pp_a <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb830-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-3" data-line-number="3"><span class="st">  </span><span class="kw">stat_histintervalh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>),</a>
<a class="sourceLine" id="cb830-4" data-line-number="4">                     <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">slab_color =</span> <span class="st">&quot;grey92&quot;</span>,</a>
<a class="sourceLine" id="cb830-5" data-line-number="5">                     <span class="dt">breaks =</span> <span class="dv">30</span>, <span class="dt">slab_size =</span> <span class="fl">.4</span>, <span class="dt">outline_bars =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-6" data-line-number="6"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;The posterior for the probability, given the</span><span class="ch">\n</span><span class="st">weighted combination of fit10.1 and fit10.2&quot;</span>,</a>
<a class="sourceLine" id="cb830-8" data-line-number="8">       <span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p)(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span><span class="kw">italic</span>(D)))) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-10" data-line-number="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-55-1.png" style="display: block; margin: auto;" /></p>
<p>As Kruschke concluded, “you can see the contribution of <span class="math inline">\(p(\theta | D, \omega = 0.25)\)</span> as the extended leftward tail” (p. 289). Interestingly enough, that looks a lot like the density we made with grid approximation in Figure 10.3, doesn’t it?</p>
</div>
<div id="model-complexity-naturally-accounted-for" class="section level2">
<h2><span class="header-section-number">10.5</span> Model complexity naturally accounted for</h2>
<blockquote>
<p>A complex model (usually) has an inherent advantage over a simpler model because the complex model can find some combination of its parameter values that match the data better than the simpler model. There are so many more parameter options in the complex model that one of those options is likely to fit the data better than any of the fewer options in the simpler model. The problem is that data are contaminated by random noise, and we do not want to always choose the more complex model merely because it can better fit noise. Without some way of accounting for model complexity, the presence of noise in data will tend to favor the complex model.</p>
<p>Bayesian model comparison compensates for model complexity by the fact that each model must have a prior distribution over its parameters, and more complex models must dilute their prior distributions over larger parameter spaces than simpler models. Thus, even if a complex model has some particular combination of parameter values that fit the data well, the prior probability of that particular combination must be small because the prior is spread thinly over the broad parameter space. (pp. 289–290)</p>
</blockquote>
<p>Now our two models are:</p>
<ul>
<li><span class="math inline">\(p(\theta | D, \kappa = 2000)\)</span> (i.e., the “must-be-fair” model) and</li>
<li><span class="math inline">\(p(\theta | D, \kappa = 2)\)</span> (i.e., the “anything’s-possible” model).</li>
</ul>
<p>They look like this.</p>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb831-1" data-line-number="1"><span class="co"># how granular to you want the theta sequence?</span></a>
<a class="sourceLine" id="cb831-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="fl">1e3</span></a>
<a class="sourceLine" id="cb831-3" data-line-number="3"></a>
<a class="sourceLine" id="cb831-4" data-line-number="4"><span class="co"># simulate the data</span></a>
<a class="sourceLine" id="cb831-5" data-line-number="5"><span class="kw">tibble</span>(<span class="dt">omega =</span> <span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb831-6" data-line-number="6">       <span class="dt">kappa =</span> <span class="kw">c</span>(<span class="dv">1000</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb831-7" data-line-number="7">       <span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;The must-be-fair model&quot;</span>, <span class="st">&quot;The anything&#39;s-possible model&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb831-8" data-line-number="8"><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(omega, kappa, model),</a>
<a class="sourceLine" id="cb831-9" data-line-number="9">         <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> n)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb831-10" data-line-number="10"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dbeta</span>(theta, </a>
<a class="sourceLine" id="cb831-11" data-line-number="11">                         <span class="dt">shape1 =</span>      omega  <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb831-12" data-line-number="12">                         <span class="dt">shape2 =</span> (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb831-13" data-line-number="13"><span class="st">  </span></a>
<a class="sourceLine" id="cb831-14" data-line-number="14"><span class="st">  </span><span class="co"># plot</span></a>
<a class="sourceLine" id="cb831-15" data-line-number="15"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density)) <span class="op">+</span></a>
<a class="sourceLine" id="cb831-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb831-17" data-line-number="17"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb831-18" data-line-number="18"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Note that in this case, their y-axes are on the same scale.&quot;</span>,</a>
<a class="sourceLine" id="cb831-19" data-line-number="19">       <span class="dt">x =</span> <span class="kw">expression</span>(theta)) <span class="op">+</span></a>
<a class="sourceLine" id="cb831-20" data-line-number="20"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb831-21" data-line-number="21"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>model)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-56-1.png" style="display: block; margin: auto;" /></p>
<p>Here’s how you might compute the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> values for the corresponding beta distributions.</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb832-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">omega =</span> <span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb832-2" data-line-number="2">       <span class="dt">kappa =</span> <span class="kw">c</span>(<span class="dv">1000</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb832-3" data-line-number="3">       <span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;The must-be-fair model&quot;</span>, <span class="st">&quot;The anything&#39;s-possible model&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb832-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">alpha =</span>      omega  <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb832-5" data-line-number="5">         <span class="dt">beta  =</span> (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>omega) <span class="op">*</span><span class="st"> </span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   omega kappa model                         alpha  beta
##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt;
## 1   0.5  1000 The must-be-fair model          500   500
## 2   0.5     2 The anything&#39;s-possible model     1     1</code></pre>
<p>With those in hand, we can use our <code>p_d()</code> function to compute the Bayes factor based on flipping a coin <span class="math inline">\(N = 20\)</span> times and observing <span class="math inline">\(z = 15\)</span> heads.</p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb834-1" data-line-number="1"><span class="co"># the data summaries</span></a>
<a class="sourceLine" id="cb834-2" data-line-number="2">z &lt;-<span class="st"> </span><span class="dv">15</span></a>
<a class="sourceLine" id="cb834-3" data-line-number="3">n &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb834-4" data-line-number="4"></a>
<a class="sourceLine" id="cb834-5" data-line-number="5"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span>, <span class="dt">b =</span> <span class="dv">500</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.3229023</code></pre>
<p>Let’s try again, this time supposing we observe <span class="math inline">\(z = 15\)</span> heads out of <span class="math inline">\(N = 20\)</span> coin flips.</p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb836-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="dv">11</span></a>
<a class="sourceLine" id="cb836-2" data-line-number="2"></a>
<a class="sourceLine" id="cb836-3" data-line-number="3"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span>, <span class="dt">b =</span> <span class="dv">500</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 3.337148</code></pre>
<blockquote>
<p>The anything’s-possible model loses because it pays the price of having a small prior probability on the values of <span class="math inline">\(\theta\)</span> near the data proportion, while the must-be-fair model has large prior probability on <span class="math inline">\(\theta\)</span> values sufficiently near the data proportion to be credible. Thus, in Bayesian model comparison, a simpler model can win if the data are consistent with it, even if the complex model fits just as well. The complex model pays the price of having small prior probability on parameter values that describe simple data. (p. 291)</p>
</blockquote>
<div id="caveats-regarding-nested-model-comparison." class="section level3">
<h3><span class="header-section-number">10.5.1</span> Caveats regarding nested model comparison.</h3>
<blockquote>
<p>A frequently encountered special case of comparing models of different complexity occurs when one model is “nested” within the other. Consider a model that implements all the meaningful parameters we can contemplate for the particular application. We call that the full model. We might consider various restrictions of those parameters, such as setting some of them to zero, or forcing some to be equal to each other. A model with such a restriction is said to be nested within the full model. (p. 291)</p>
</blockquote>
<p>Kruschke didn’t walk out the examples in this section. But for the sake of practice, let’s work through the first one. “Recall the hierarchical model of baseball batting abilities” from Chapter 9 (p. 291). Let’s reload those data.</p>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb838-1" data-line-number="1">my_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data.R/BattingAverage.csv&quot;</span>)</a>
<a class="sourceLine" id="cb838-2" data-line-number="2"></a>
<a class="sourceLine" id="cb838-3" data-line-number="3"><span class="kw">glimpse</span>(my_data)</a></code></pre></div>
<pre><code>## Observations: 948
## Variables: 6
## $ Player       &lt;chr&gt; &quot;Fernando Abad&quot;, &quot;Bobby Abreu&quot;, &quot;Tony Abreu&quot;, &quot;Dustin Ac…
## $ PriPos       &lt;chr&gt; &quot;Pitcher&quot;, &quot;Left Field&quot;, &quot;2nd Base&quot;, &quot;2nd Base&quot;, &quot;1st Ba…
## $ Hits         &lt;dbl&gt; 1, 53, 18, 137, 21, 0, 0, 2, 150, 167, 0, 128, 66, 3, 1,…
## $ AtBats       &lt;dbl&gt; 7, 219, 70, 607, 86, 1, 1, 20, 549, 576, 1, 525, 275, 12…
## $ PlayerNumber &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ PriPosNumber &lt;dbl&gt; 1, 7, 4, 4, 3, 1, 1, 3, 3, 4, 1, 5, 4, 2, 7, 4, 6, 8, 9,…</code></pre>
<p>“The full model has a distinct modal batting ability, <span class="math inline">\(\omega_c\)</span> , for each of the nine fielding positions. The full model also has distinct concentration parameters for each of the nine positions” (p. 291). Let’s fit that model again.</p>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb840-1" data-line-number="1">fit9<span class="fl">.2</span> &lt;-</a>
<a class="sourceLine" id="cb840-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb840-3" data-line-number="3">      <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit),</a>
<a class="sourceLine" id="cb840-4" data-line-number="4">      Hits <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(AtBats) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>PriPos) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>PriPos<span class="op">:</span>Player),</a>
<a class="sourceLine" id="cb840-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb840-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd)),</a>
<a class="sourceLine" id="cb840-7" data-line-number="7">      <span class="dt">iter =</span> <span class="dv">3500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">cores =</span> <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb840-8" data-line-number="8">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.99</span>),</a>
<a class="sourceLine" id="cb840-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">9</span>,</a>
<a class="sourceLine" id="cb840-10" data-line-number="10">      <span class="dt">file =</span> <span class="st">&quot;fits/fit09.02&quot;</span>)</a></code></pre></div>
<p>Next we’ll consider a restricted version of <code>fit9.2</code> “in which all infielders (first base, second base, etc.) are grouped together versus all outfielders (right field, center field, and left field). In this restricted model, we are forcing the modal batting abilities of all the outfielders to be the same, that is, <span class="math inline">\(\omega_\text{left field} = \omega_\text{center field} = \omega_\text{right field}\)</span>” (p. 291). To fit that model, we’ll need to make a new variable <code>PriPos_small</code> which is identical to its parent variable <code>PriPos</code> except that it collapses those three positions into our new category <code>Outfield</code>.</p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb841-1" data-line-number="1"> my_data &lt;-</a>
<a class="sourceLine" id="cb841-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb841-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">PriPos_small =</span> <span class="kw">if_else</span>(PriPos <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Center Field&quot;</span>, <span class="st">&quot;Left Field&quot;</span>, <span class="st">&quot;Right Field&quot;</span>),</a>
<a class="sourceLine" id="cb841-4" data-line-number="4">                                <span class="st">&quot;Outfield&quot;</span>, PriPos))</a></code></pre></div>
<p>Now use <code>update()</code> to fit the restricted model.</p>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" data-line-number="1">fit10<span class="fl">.5</span> &lt;-</a>
<a class="sourceLine" id="cb842-2" data-line-number="2"><span class="st">  </span><span class="kw">update</span>(fit9<span class="fl">.2</span>,</a>
<a class="sourceLine" id="cb842-3" data-line-number="3">         <span class="dt">newdata =</span> my_data,</a>
<a class="sourceLine" id="cb842-4" data-line-number="4">         <span class="dt">formula =</span> Hits <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(AtBats) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>PriPos_small) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>PriPos_small<span class="op">:</span>Player),</a>
<a class="sourceLine" id="cb842-5" data-line-number="5">         <span class="dt">iter =</span> <span class="dv">3500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">cores =</span> <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb842-6" data-line-number="6">         <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.99</span>),</a>
<a class="sourceLine" id="cb842-7" data-line-number="7">         <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb842-8" data-line-number="8">         <span class="dt">file =</span> <span class="st">&quot;fits/fit10.05&quot;</span>)</a></code></pre></div>
<p>Unlike with what Kruschke alluded to in the prose, here we’ll compare the two models with the WAIC.</p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb843-1" data-line-number="1">fit9<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit9<span class="fl">.2</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)</a>
<a class="sourceLine" id="cb843-2" data-line-number="2">fit10<span class="fl">.5</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.5</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)</a>
<a class="sourceLine" id="cb843-3" data-line-number="3"></a>
<a class="sourceLine" id="cb843-4" data-line-number="4"><span class="kw">loo_compare</span>(fit9<span class="fl">.2</span>, fit10<span class="fl">.5</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)</a></code></pre></div>
<pre><code>##         elpd_diff se_diff
## fit9.2   0.0       0.0   
## fit10.5 -0.3       1.2</code></pre>
<p>Based on the WAIC difference score, they’re near equivalent. Now let’s see how their WAIC weights shake out.</p>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb845-1" data-line-number="1"><span class="kw">model_weights</span>(fit9<span class="fl">.2</span>, fit10<span class="fl">.5</span>, <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)</a></code></pre></div>
<pre><code>##  fit9.2 fit10.5 
##    0.58    0.42</code></pre>
<p>In this case, just a little more of the weight went to the full model, <code>fit9.2</code>. The overall pattern between the WAIC difference and the WAIC weights was uncertainty. Make sure to use good substantive reasoning when comparing models.</p>
</div>
</div>
<div id="extreme-sensitivity-to-the-prior-distribution" class="section level2">
<h2><span class="header-section-number">10.6</span> Extreme sensitivity to the prior distribution</h2>
<blockquote>
<p>In many realistic applications of Bayesian model comparison, the theoretical emphasis is on the difference between the models’ likelihood functions. For example, one theory predicts planetary motions based on elliptical orbits around the sun, and another theory predicts planetary motions based on circular cycles and epicycles around the earth. The two models involve very different parameters. In these sorts of models, the form of the prior distribution on the parameters is not a focus, and is often an afterthought. But, when doing Bayesian model comparison, the form of the prior is crucial because the Bayes factor integrates the likelihood function weighted by the prior distribution. (p. 292)</p>
</blockquote>
<p>However, “the sensitivity of Bayes factors to prior distributions is well known in the literature (e.g., <a href="https://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf">Kass &amp; Raftery, 1995</a>; <a href="https://psycnet.apa.org/record/2008-17435-006">Liu &amp; Aitkin, 2008</a>; <a href="https://ppw.kuleuven.be/okp/_pdf/Vanpaemel2010PSITT.pdf">Vanpaemel, 2010</a>),” and furthermore, when comparing Bayesian models using the methods Kruschke outlined in this chapter of the text, “different forms of vague priors can yield very different Bayes factors” (p. 293).</p>
<p>In the two BFs to follow, we compare the must-be-fair model and the anything’s-possible models from 10.5 to new data: <span class="math inline">\(z = 65, N = 100\)</span>.</p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb847-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="dv">65</span></a>
<a class="sourceLine" id="cb847-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="dv">100</span> </a>
<a class="sourceLine" id="cb847-3" data-line-number="3"></a>
<a class="sourceLine" id="cb847-4" data-line-number="4"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span>, <span class="dt">b =</span> <span class="dv">500</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.125287</code></pre>
<p>The resulting 0.13 favored the anything’s-possible model.</p>
<p>Another way to express the anything’s-possible model is with the Haldane prior, which sets the two parameters within the beta distribution to be a) equivalent and b) quite small (i.e., 0.01 in this case).</p>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb849-1" data-line-number="1"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span>, <span class="dt">b =</span> <span class="dv">500</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="fl">.01</span>, <span class="dt">b =</span> <span class="fl">.01</span>)</a></code></pre></div>
<pre><code>## [1] 5.728066</code></pre>
<p>Now we flipped to favoring the must-be-fair model. You might be asking, <em>Wait, kind of distribution did that Haldane prior produce?</em> Here we compare it to the <span class="math inline">\(\operatorname{beta} (1, 1)\)</span>.</p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb851-1" data-line-number="1"><span class="co"># how granular to you want the theta sequence?</span></a>
<a class="sourceLine" id="cb851-2" data-line-number="2">length &lt;-<span class="st"> </span><span class="fl">1e3</span></a>
<a class="sourceLine" id="cb851-3" data-line-number="3"></a>
<a class="sourceLine" id="cb851-4" data-line-number="4"><span class="co"># simulate the data</span></a>
<a class="sourceLine" id="cb851-5" data-line-number="5"><span class="kw">tibble</span>(<span class="dt">alpha =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">.01</span>),</a>
<a class="sourceLine" id="cb851-6" data-line-number="6">       <span class="dt">beta  =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">.01</span>),</a>
<a class="sourceLine" id="cb851-7" data-line-number="7">       <span class="dt">model =</span> <span class="kw">factor</span>(<span class="kw">c</span>(<span class="st">&quot;Uninformative prior, beta(1, 1)&quot;</span>, <span class="st">&quot;Haldane prior, beta(0.01, 0.01)&quot;</span>),</a>
<a class="sourceLine" id="cb851-8" data-line-number="8">                      <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Uninformative prior, beta(1, 1)&quot;</span>, <span class="st">&quot;Haldane prior, beta(0.01, 0.01)&quot;</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb851-9" data-line-number="9"><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(alpha, beta, model),</a>
<a class="sourceLine" id="cb851-10" data-line-number="10">         <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> length)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-11" data-line-number="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dbeta</span>(theta, </a>
<a class="sourceLine" id="cb851-12" data-line-number="12">                         <span class="dt">shape1 =</span> alpha, </a>
<a class="sourceLine" id="cb851-13" data-line-number="13">                         <span class="dt">shape2 =</span> beta)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-14" data-line-number="14"><span class="st">  </span></a>
<a class="sourceLine" id="cb851-15" data-line-number="15"><span class="st">  </span><span class="co"># plot</span></a>
<a class="sourceLine" id="cb851-16" data-line-number="16"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density)) <span class="op">+</span></a>
<a class="sourceLine" id="cb851-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-18" data-line-number="18"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb851-19" data-line-number="19"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;We have two anything’s-possible models.&quot;</span>,</a>
<a class="sourceLine" id="cb851-20" data-line-number="20">       <span class="dt">subtitle =</span> <span class="st">&quot;These y-axes are on the same scale.&quot;</span>,</a>
<a class="sourceLine" id="cb851-21" data-line-number="21">       <span class="dt">x =</span> <span class="kw">expression</span>(theta)) <span class="op">+</span></a>
<a class="sourceLine" id="cb851-22" data-line-number="22"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb851-23" data-line-number="23"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>model)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-66-1.png" style="display: block; margin: auto;" /></p>
<p>Before we can complete the analyses of this subsection, we’ll need to define our version of Kruschke’s <code>HDIofICDF function()</code>, <code>hdi_of_icdf()</code>. Like we’ve done in previous chapters, here we mildly reformat the function.</p>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" data-line-number="1">hdi_of_icdf &lt;-<span class="st"> </span><span class="cf">function</span>(name, <span class="dt">width =</span> <span class="fl">.95</span>, <span class="dt">tol =</span> <span class="fl">1e-8</span>, ... ) {</a>
<a class="sourceLine" id="cb852-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb852-3" data-line-number="3">  incredible_mass &lt;-<span class="st"> </span><span class="fl">1.0</span> <span class="op">-</span><span class="st"> </span>width</a>
<a class="sourceLine" id="cb852-4" data-line-number="4">  interval_width &lt;-<span class="st"> </span><span class="cf">function</span>(low_tail_prob, name, width, ...) {</a>
<a class="sourceLine" id="cb852-5" data-line-number="5">    <span class="kw">name</span>(width <span class="op">+</span><span class="st"> </span>low_tail_prob, ...) <span class="op">-</span><span class="st"> </span><span class="kw">name</span>(low_tail_prob, ...)</a>
<a class="sourceLine" id="cb852-6" data-line-number="6">  }</a>
<a class="sourceLine" id="cb852-7" data-line-number="7">  opt_info &lt;-<span class="st"> </span><span class="kw">optimize</span>(interval_width, <span class="kw">c</span>(<span class="dv">0</span>, incredible_mass), </a>
<a class="sourceLine" id="cb852-8" data-line-number="8">                       <span class="dt">name =</span> name, <span class="dt">width =</span> width, </a>
<a class="sourceLine" id="cb852-9" data-line-number="9">                       <span class="dt">tol =</span> tol, ...)</a>
<a class="sourceLine" id="cb852-10" data-line-number="10">  hdi_lower_tail_prob &lt;-<span class="st"> </span>opt_info<span class="op">$</span>minimum</a>
<a class="sourceLine" id="cb852-11" data-line-number="11">  </a>
<a class="sourceLine" id="cb852-12" data-line-number="12">  <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">name</span>(hdi_lower_tail_prob, ...),</a>
<a class="sourceLine" id="cb852-13" data-line-number="13">           <span class="kw">name</span>(width <span class="op">+</span><span class="st"> </span>hdi_lower_tail_prob, ...)))</a>
<a class="sourceLine" id="cb852-14" data-line-number="14">  </a>
<a class="sourceLine" id="cb852-15" data-line-number="15">}</a></code></pre></div>
<p>And here we’ll make a custom variant to be more useful within the context of <code>map2()</code>.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb853-1" data-line-number="1">hdi_of_qbeta &lt;-<span class="st"> </span><span class="cf">function</span>(shape1, shape2) {</a>
<a class="sourceLine" id="cb853-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb853-3" data-line-number="3">  <span class="kw">hdi_of_icdf</span>(<span class="dt">name =</span> qbeta,</a>
<a class="sourceLine" id="cb853-4" data-line-number="4">              <span class="dt">shape1 =</span> shape1,</a>
<a class="sourceLine" id="cb853-5" data-line-number="5">              <span class="dt">shape2 =</span> shape2) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb853-6" data-line-number="6"><span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb853-7" data-line-number="7"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">level =</span> <span class="kw">c</span>(<span class="st">&quot;ll&quot;</span>, <span class="st">&quot;ul&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb853-8" data-line-number="8"><span class="st">    </span><span class="kw">spread</span>(<span class="dt">key =</span> level, <span class="dt">value =</span> <span class="st">&quot;.&quot;</span>)</a>
<a class="sourceLine" id="cb853-9" data-line-number="9">  </a>
<a class="sourceLine" id="cb853-10" data-line-number="10">}</a></code></pre></div>
<p>Recall that when we combine a <span class="math inline">\(\operatorname{beta} (\theta | \alpha, \beta)\)</span> prior with the results of a Bernoulli likelihood, we get a posterior defined by <span class="math inline">\(\operatorname{beta} (\theta | z + \alpha, N - z + \beta)\)</span>.</p>
<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" data-line-number="1">d &lt;-</a>
<a class="sourceLine" id="cb854-2" data-line-number="2"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">model   =</span> <span class="kw">c</span>(<span class="st">&quot;Uniform&quot;</span>, <span class="st">&quot;Haldane&quot;</span>),</a>
<a class="sourceLine" id="cb854-3" data-line-number="3">         <span class="dt">prior_a =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">.01</span>),</a>
<a class="sourceLine" id="cb854-4" data-line-number="4">         <span class="dt">prior_b =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">.01</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb854-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">posterior_a =</span> z <span class="op">+</span><span class="st"> </span>prior_a,</a>
<a class="sourceLine" id="cb854-6" data-line-number="6">         <span class="dt">posterior_b =</span> n <span class="op">-</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span>prior_b)</a>
<a class="sourceLine" id="cb854-7" data-line-number="7"></a>
<a class="sourceLine" id="cb854-8" data-line-number="8">d</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   model   prior_a prior_b posterior_a posterior_b
##   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1 Uniform    1       1           66          36  
## 2 Haldane    0.01    0.01        65.0        35.0</code></pre>
<p>Now we’ll use our custom <code>hdi_of_qbeta()</code> to compute the HDIs.</p>
<div class="sourceCode" id="cb856"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb856-1" data-line-number="1">(</a>
<a class="sourceLine" id="cb856-2" data-line-number="2">  d &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb856-3" data-line-number="3"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb856-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">levels =</span> <span class="kw">map2</span>(posterior_a, posterior_b, hdi_of_qbeta)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb856-5" data-line-number="5"><span class="st">  </span><span class="kw">unnest</span>(levels)</a>
<a class="sourceLine" id="cb856-6" data-line-number="6"> )</a></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   model   prior_a prior_b posterior_a posterior_b    ll    ul
##   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Uniform    1       1           66          36   0.554 0.738
## 2 Haldane    0.01    0.01        65.0        35.0 0.556 0.742</code></pre>
<p>Let’s compare those HDIs in a plot.</p>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb858-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb858-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ll,    <span class="dt">xend =</span> ul,</a>
<a class="sourceLine" id="cb858-3" data-line-number="3">             <span class="dt">y =</span> model, <span class="dt">yend =</span> model)) <span class="op">+</span></a>
<a class="sourceLine" id="cb858-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">size =</span> <span class="fl">.75</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb858-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(theta), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb858-6" data-line-number="6"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Those two sets of HDIs are quite similar.</span><span class="ch">\n</span><span class="st">It almost seems silly their respective BFs</span><span class="ch">\n</span><span class="st">are so different.&quot;</span>,</a>
<a class="sourceLine" id="cb858-7" data-line-number="7">       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb858-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb858-9" data-line-number="9">        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb858-10" data-line-number="10">        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-71-1.png" style="display: block; margin: auto;" /></p>
<p>“The HDIs are virtually identical. In particular, for either prior, the posterior distribution rules out <span class="math inline">\(\theta = 0.5\)</span>, which is to say that the must-be-fair hypothesis is not among the credible values” (p. 294).</p>
<div id="priors-of-different-models-should-be-equally-informed." class="section level3">
<h3><span class="header-section-number">10.6.1</span> Priors of different models should be equally informed.</h3>
<p>“We have established that seemingly innocuous changes in the vagueness of a vague prior can dramatically change a model’s marginal likelihood, and hence its Bayes factor in comparison with other models. What can be done to ameliorate the problem” (p. 294)? Kruschke posed one method might be taking a small representative portion of the data in hand and use them to make an empirically-based prior for the remaining set of data. From our previous example, “suppose that the 10% subset has 6 heads in 10 flips, so the remaining 90% of the data has <span class="math inline">\(z = 65 − 6\)</span> and <span class="math inline">\(N = 100 − 10\)</span>” (p. 294).</p>
<p>Here are the new Bayes factors based on that method.</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb859-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="dv">65</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb859-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb859-3" data-line-number="3"></a>
<a class="sourceLine" id="cb859-4" data-line-number="4"><span class="co"># Peaked vs Uniform</span></a>
<a class="sourceLine" id="cb859-5" data-line-number="5"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">b =</span> <span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span>   <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">b =</span>   <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.05570509</code></pre>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb861-1" data-line-number="1"><span class="co"># Peaked vs Haldane</span></a>
<a class="sourceLine" id="cb861-2" data-line-number="2"><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">b =</span> <span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span>) <span class="op">/</span><span class="st"> </span><span class="kw">p_d</span>(z, n, <span class="dt">a =</span> <span class="fl">.01</span> <span class="op">+</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">b =</span> <span class="fl">.01</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.05748123</code></pre>
<p>Now the two Bayes Factors are nearly the same.</p>
<p>It’s not in the text, but let’s compare these three models using <strong>brms</strong>, information criteria, model weights, model averaging, and posterior predictive checks. First, we’ll save the <span class="math inline">\(z\)</span> and <span class="math inline">\(N\)</span> information as a tibble with a series of 0s and 1s.</p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb863-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="dv">65</span></a>
<a class="sourceLine" id="cb863-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb863-3" data-line-number="3"></a>
<a class="sourceLine" id="cb863-4" data-line-number="4">trial_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y =</span> <span class="kw">rep</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">times =</span> <span class="kw">c</span>(n <span class="op">-</span><span class="st"> </span>z, z)))</a>
<a class="sourceLine" id="cb863-5" data-line-number="5"></a>
<a class="sourceLine" id="cb863-6" data-line-number="6"><span class="kw">glimpse</span>(trial_data)</a></code></pre></div>
<pre><code>## Observations: 100
## Variables: 1
## $ y &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</code></pre>
<p>Next, fit the three models with <code>brms::brm()</code>.</p>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb865-1" data-line-number="1">fit10<span class="fl">.6</span> &lt;-</a>
<a class="sourceLine" id="cb865-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> trial_data, </a>
<a class="sourceLine" id="cb865-3" data-line-number="3">      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> identity),</a>
<a class="sourceLine" id="cb865-4" data-line-number="4">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb865-5" data-line-number="5">      <span class="kw">prior</span>(<span class="kw">beta</span>(<span class="dv">500</span>, <span class="dv">500</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb865-6" data-line-number="6">      <span class="dt">iter =</span> <span class="dv">11000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb865-7" data-line-number="7">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb865-8" data-line-number="8">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.06&quot;</span>)</a>
<a class="sourceLine" id="cb865-9" data-line-number="9"></a>
<a class="sourceLine" id="cb865-10" data-line-number="10">fit10<span class="fl">.7</span> &lt;-</a>
<a class="sourceLine" id="cb865-11" data-line-number="11"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> trial_data, </a>
<a class="sourceLine" id="cb865-12" data-line-number="12">      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> identity),</a>
<a class="sourceLine" id="cb865-13" data-line-number="13">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb865-14" data-line-number="14">      <span class="co"># Uniform</span></a>
<a class="sourceLine" id="cb865-15" data-line-number="15">      <span class="kw">prior</span>(<span class="kw">beta</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb865-16" data-line-number="16">      <span class="dt">iter =</span> <span class="dv">11000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb865-17" data-line-number="17">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb865-18" data-line-number="18">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.07&quot;</span>)</a>
<a class="sourceLine" id="cb865-19" data-line-number="19"></a>
<a class="sourceLine" id="cb865-20" data-line-number="20">fit10<span class="fl">.8</span> &lt;-</a>
<a class="sourceLine" id="cb865-21" data-line-number="21"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> trial_data, </a>
<a class="sourceLine" id="cb865-22" data-line-number="22">      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> identity),</a>
<a class="sourceLine" id="cb865-23" data-line-number="23">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb865-24" data-line-number="24">      <span class="co"># Haldane</span></a>
<a class="sourceLine" id="cb865-25" data-line-number="25">      <span class="kw">prior</span>(<span class="kw">beta</span>(<span class="fl">0.01</span>, <span class="fl">0.01</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb865-26" data-line-number="26">      <span class="dt">iter =</span> <span class="dv">11000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb865-27" data-line-number="27">      <span class="dt">seed =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb865-28" data-line-number="28">      <span class="dt">file =</span> <span class="st">&quot;fits/fit10.08&quot;</span>)</a></code></pre></div>
<p>Compare the models by the LOO.</p>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb866-1" data-line-number="1">fit10<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.6</span>, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb866-2" data-line-number="2">fit10<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.7</span>, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb866-3" data-line-number="3">fit10<span class="fl">.8</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit10<span class="fl">.8</span>, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb866-4" data-line-number="4"></a>
<a class="sourceLine" id="cb866-5" data-line-number="5"><span class="kw">loo_compare</span>(fit10<span class="fl">.6</span>, fit10<span class="fl">.7</span>, fit10<span class="fl">.8</span>)</a></code></pre></div>
<pre><code>##         elpd_diff se_diff
## fit10.7  0.0       0.0   
## fit10.8  0.0       0.1   
## fit10.6 -2.9       2.7</code></pre>
<p>Based on the LOO comparisons, none of the three models was a clear favorite. Although both versions of the anything’s-possible model (i.e., <code>fit10.7</code> and <code>fit10.8</code>) had lower numeric estimates than the must-be-fair model (i.e., <code>fit10.6</code>), the standard errors on the difference scores were the same magnitude as the difference estimates themselves. As for comparing the two variants of the anything’s-possible model directly, their LOO estimates were almost indistinguishable.</p>
<p>Now let’s see what happens when we compute their model weights. Here we’ll contrast the LOO weights with the stacking weights.</p>
<div class="sourceCode" id="cb868"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb868-1" data-line-number="1">mw &lt;-</a>
<a class="sourceLine" id="cb868-2" data-line-number="2"><span class="st">  </span><span class="kw">model_weights</span>(fit10<span class="fl">.6</span>, fit10<span class="fl">.7</span>, fit10<span class="fl">.8</span>, <span class="dt">weights =</span> <span class="st">&quot;stacking&quot;</span>)</a>
<a class="sourceLine" id="cb868-3" data-line-number="3"></a>
<a class="sourceLine" id="cb868-4" data-line-number="4">mw <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb868-5" data-line-number="5"><span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## fit10.6 fit10.7 fit10.8 
##    0.12    0.33    0.55</code></pre>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb870-1" data-line-number="1"><span class="kw">model_weights</span>(fit10<span class="fl">.6</span>, fit10<span class="fl">.7</span>, fit10<span class="fl">.8</span>, <span class="dt">weights =</span> <span class="st">&quot;loo&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb870-2" data-line-number="2"><span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## fit10.6 fit10.7 fit10.8 
##    0.03    0.49    0.48</code></pre>
<p>Here the evidence varied by the specific weight. Across both, the model with the Haldane prior (<code>fit10.8</code>) did arguably the best. But the model with the uniform prior (<code>fit10.9</code>) was clearly in the running. Overall, the evidence for one versus another was weak.</p>
<p>Like we did earlier with <code>fit10.1</code> and <code>fit10.2</code>, we can use the <code>pp_average()</code> function to compute the stacking weighted posterior for <span class="math inline">\(\theta\)</span>.</p>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb872-1" data-line-number="1"><span class="kw">pp_average</span>(fit10<span class="fl">.6</span>, fit10<span class="fl">.7</span>, fit10<span class="fl">.8</span>, </a>
<a class="sourceLine" id="cb872-2" data-line-number="2">           <span class="dt">newdata =</span> nd,</a>
<a class="sourceLine" id="cb872-3" data-line-number="3">           <span class="dt">weights =</span> mw,</a>
<a class="sourceLine" id="cb872-4" data-line-number="4">           <span class="dt">method =</span> <span class="st">&quot;fitted&quot;</span>,</a>
<a class="sourceLine" id="cb872-5" data-line-number="5">           <span class="dt">summary =</span> F) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb872-6" data-line-number="6"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb872-7" data-line-number="7"><span class="st">  </span></a>
<a class="sourceLine" id="cb872-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> V1, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb872-9" data-line-number="9"><span class="st">  </span><span class="kw">stat_histintervalh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>),</a>
<a class="sourceLine" id="cb872-10" data-line-number="10">                     <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">slab_color =</span> <span class="st">&quot;grey92&quot;</span>,</a>
<a class="sourceLine" id="cb872-11" data-line-number="11">                     <span class="dt">breaks =</span> <span class="dv">30</span>, <span class="dt">slab_size =</span> <span class="fl">.25</span>, <span class="dt">outline_bars =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb872-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb872-13" data-line-number="13"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;The posterior for the probability, given the weighted</span><span class="ch">\n</span><span class="st">combination of fit10.6, fit10.7, and fit10.8&quot;</span>,</a>
<a class="sourceLine" id="cb872-14" data-line-number="14">       <span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p)(theta<span class="op">*</span><span class="st">&quot;|&quot;</span><span class="op">*</span><span class="kw">italic</span>(D)))) <span class="op">+</span></a>
<a class="sourceLine" id="cb872-15" data-line-number="15"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb872-16" data-line-number="16"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-74-1.png" style="display: block; margin: auto;" /></p>
<p>Did you notice the <code>weights = mw</code> argument, there? From the <code>pp_average.brmsfit</code> section of the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf"><strong>brms</strong> reference manual (version 2.11.1)</a>, we read “<code>weights</code> may also be be a numeric vector of pre-specified weights.” Since we saved the results of <code>model_weights()</code> as an object <code>mw</code>, we were able to capitalize on that feature. If you leave out that argument, you’ll have to wait a bit for <strong>brms</strong> to compute those weights again from scratch.</p>
<p>And just for the sake of practice, we can also compare the models with separate posterior predictive checks using <code>pp_check()</code>.</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb873-1" data-line-number="1">p1 &lt;-</a>
<a class="sourceLine" id="cb873-2" data-line-number="2"><span class="st">  </span><span class="kw">pp_check</span>(fit10<span class="fl">.6</span>, <span class="dt">type =</span> <span class="st">&quot;bars&quot;</span>, <span class="dt">nsamples =</span> <span class="fl">1e3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb873-3" data-line-number="3"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;fit10.6&quot;</span>,</a>
<a class="sourceLine" id="cb873-4" data-line-number="4">          <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;beta&quot;</span><span class="op">*</span>(<span class="dv">500</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">500</span>)))</a>
<a class="sourceLine" id="cb873-5" data-line-number="5"></a>
<a class="sourceLine" id="cb873-6" data-line-number="6">p2 &lt;-</a>
<a class="sourceLine" id="cb873-7" data-line-number="7"><span class="st">  </span><span class="kw">pp_check</span>(fit10<span class="fl">.7</span>, <span class="dt">type =</span> <span class="st">&quot;bars&quot;</span>, <span class="dt">nsamples =</span> <span class="fl">1e3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb873-8" data-line-number="8"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;fit10.7&quot;</span>,</a>
<a class="sourceLine" id="cb873-9" data-line-number="9">          <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;beta&quot;</span><span class="op">*</span>(<span class="dv">1</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">1</span>)))</a>
<a class="sourceLine" id="cb873-10" data-line-number="10"></a>
<a class="sourceLine" id="cb873-11" data-line-number="11">p3 &lt;-</a>
<a class="sourceLine" id="cb873-12" data-line-number="12"><span class="st">  </span><span class="kw">pp_check</span>(fit10<span class="fl">.8</span>, <span class="dt">type =</span> <span class="st">&quot;bars&quot;</span>, <span class="dt">nsamples =</span> <span class="fl">1e3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb873-13" data-line-number="13"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;fit10.8&quot;</span>,</a>
<a class="sourceLine" id="cb873-14" data-line-number="14">          <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;beta&quot;</span><span class="op">*</span>(<span class="fl">0.01</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="fl">0.01</span>)))</a>
<a class="sourceLine" id="cb873-15" data-line-number="15"></a>
<a class="sourceLine" id="cb873-16" data-line-number="16">((p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span>p3) <span class="op">&amp;</span><span class="st"> </span></a>
<a class="sourceLine" id="cb873-17" data-line-number="17"><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">&amp;</span></a>
<a class="sourceLine" id="cb873-18" data-line-number="18"><span class="st">    </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">80</span>) <span class="op">&amp;</span></a>
<a class="sourceLine" id="cb873-19" data-line-number="19"><span class="st">    </span><span class="kw">theme_grey</span>() <span class="op">&amp;</span></a>
<a class="sourceLine" id="cb873-20" data-line-number="20"><span class="st">    </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb873-21" data-line-number="21"><span class="st">  </span><span class="kw">plot_layout</span>(<span class="dt">guides =</span> <span class="st">&#39;collect&#39;</span>)</a></code></pre></div>
<p><img src="10_files/figure-gfm/unnamed-chunk-75-1.png" style="display: block; margin: auto;" /></p>
<p>Instead of the default 10, this time we used 1,000 posterior simulations from each fit, which we summarized with dot and error bars. This method did a great job showing how little <code>fit10.6</code> learned from the data. Another nice thing about this method is it reveals how similar the results are between <code>fit10.7</code> and <code>fit10.8</code>, the two alternate versions of the anything’s-possible model. Also, did you notice how we used <code>ylim(0, 80)</code> when combining the plots with <strong>patchwork</strong>? Holding the scale of the axes constant makes it easier to compare results across plots.</p>
</div>
</div>
<div id="bonus-theres-danger-ahead" class="section level2">
<h2><span class="header-section-number">10.7</span> Bonus: There’s danger ahead</h2>
<p>If you’re new to model comparison with Bayes factors, information criteria, model stacking and so on, you should know these methods are still subject to spirited debate amongst scholars. For a recent example, see Gronau and Wagenmakers’ (2019) <a href="https://link.springer.com/article/10.1007/s42113-018-0011-7"><em>Limitations of Bayesian leave-one-out cross-validation for model selection</em></a>, which criticized the LOO. Their paper was commented on by <a href="https://link.springer.com/article/10.1007/s42113-018-0019-z">Navarro (2019)</a>; <a href="https://link.springer.com/article/10.1007/s42113-018-0017-1">Chandramouli and Shiffrin (2019)</a>; and <a href="https://link.springer.com/article/10.1007/s42113-018-0020-6">Vehtari, Simpson, Yao, and Gelman (2019)</a>. You can find Gronau and Wagenmakers’ (2019) rejoinder <a href="https://link.springer.com/article/10.1007/s42113-018-0022-4">here</a>.</p>
<p>And if you love those hot scholarly twitter discussions, these topics seem to spawn one every few months or so (e.g., <a href="https://twitter.com/dan_p_simpson/status/1040885250832969728">here</a>).</p>
</div>
<div id="reference-9" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Kruschke, J. K. (2015). <em>Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan.</em> Burlington, MA: Academic Press/Elsevier.</a></p>
</div>
<div id="session-info-9" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" data-line-number="1"><span class="kw">sessionInfo</span>()</a></code></pre></div>
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.0.1.9000 bayesplot_1.7.1      brms_2.11.5         
##  [4] Rcpp_1.0.3           patchwork_1.0.0      forcats_0.4.0       
##  [7] stringr_1.4.0        dplyr_0.8.4          purrr_0.3.3         
## [10] readr_1.3.1          tidyr_1.0.2          tibble_2.1.3        
## [13] ggplot2_3.2.1        tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ggridges_0.5.2           
##   [3] rsconnect_0.8.16          markdown_1.1             
##   [5] base64enc_0.1-3           fs_1.3.1                 
##   [7] rstudioapi_0.10           farver_2.0.3             
##   [9] rstan_2.19.2              svUnit_0.7-12            
##  [11] DT_0.11                   fansi_0.4.1              
##  [13] mvtnorm_1.0-12            lubridate_1.7.4          
##  [15] xml2_1.2.2                bridgesampling_0.8-1     
##  [17] knitr_1.26                shinythemes_1.1.2        
##  [19] jsonlite_1.6.1            broom_0.5.3              
##  [21] dbplyr_1.4.2              shiny_1.4.0              
##  [23] compiler_3.6.2            httr_1.4.1               
##  [25] backports_1.1.5           assertthat_0.2.1         
##  [27] Matrix_1.2-18             fastmap_1.0.1            
##  [29] lazyeval_0.2.2            cli_2.0.1                
##  [31] later_1.0.0               htmltools_0.4.0          
##  [33] prettyunits_1.1.1         tools_3.6.2              
##  [35] igraph_1.2.4.2            coda_0.19-3              
##  [37] gtable_0.3.0              glue_1.3.1               
##  [39] reshape2_1.4.3            cellranger_1.1.0         
##  [41] vctrs_0.2.2               nlme_3.1-142             
##  [43] crosstalk_1.0.0           xfun_0.12                
##  [45] ps_1.3.0                  rvest_0.3.5              
##  [47] mime_0.8                  miniUI_0.1.1.1           
##  [49] lifecycle_0.1.0           gtools_3.8.1             
##  [51] zoo_1.8-7                 scales_1.1.0             
##  [53] colourpicker_1.0          hms_0.5.3                
##  [55] promises_1.1.0            Brobdingnag_1.2-6        
##  [57] parallel_3.6.2            inline_0.3.15            
##  [59] shinystan_2.5.0           yaml_2.2.1               
##  [61] gridExtra_2.3             StanHeaders_2.19.0       
##  [63] loo_2.2.0                 stringi_1.4.5            
##  [65] highr_0.8                 dygraphs_1.1.1.6         
##  [67] pkgbuild_1.0.6            rlang_0.4.4              
##  [69] pkgconfig_2.0.3           matrixStats_0.55.0       
##  [71] HDInterval_0.2.0          evaluate_0.14            
##  [73] lattice_0.20-38           rstantools_2.0.0         
##  [75] htmlwidgets_1.5.1         labeling_0.3             
##  [77] tidyselect_1.0.0          processx_3.4.1           
##  [79] plyr_1.8.5                magrittr_1.5             
##  [81] R6_2.4.1                  generics_0.0.2           
##  [83] DBI_1.1.0                 pillar_1.4.3             
##  [85] haven_2.2.0               withr_2.1.2              
##  [87] xts_0.12-0                abind_1.4-5              
##  [89] modelr_0.1.5              crayon_1.3.4             
##  [91] arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [93] rmarkdown_2.0             grid_3.6.2               
##  [95] readxl_1.3.1              callr_3.4.1              
##  [97] threejs_0.3.3             reprex_0.3.0             
##  [99] digest_0.6.23             xtable_1.8-4             
## [101] httpuv_1.5.2              stats4_3.6.2             
## [103] munsell_0.5.0             viridisLite_0.3.0        
## [105] shinyjs_1.1</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hierarchical-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="null-hypothesis-significance-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
